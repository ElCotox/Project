{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HVVtxpUakhW6",
        "c6Orc86IkvzK",
        "d-4P-4ISNnIK",
        "Z3O6JoP6dd4A",
        "eorNX4HulU7X",
        "jXwO4HN1uRAy"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElCotox/Project/blob/main/ESG_Rating_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep / Install"
      ],
      "metadata": {
        "id": "d7LOFUX9e1MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CELLULE 1: INSTALLATION DES DÉPENDANCES\n",
        "# Exécutez cette cellule, puis redémarrez l'environnement d'exécution.\n",
        "# ==============================================================================\n",
        "!pip install -U torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install -U \\\n",
        "  transformers timm sentencepiece accelerate bitsandbytes \\\n",
        "  sentence-transformers rank-bm25 faiss-gpu-cu12 \\\n",
        "  spacy pymupdf pillow pandas"
      ],
      "metadata": {
        "id": "80kcRKKrezn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# A) Vérifier le GPU\n",
        "print(\"--- Vérification du GPU ---\")\n",
        "!nvidia-smi\n",
        "\n",
        "# B) Monter Google Drive\n",
        "print(\"\\n--- Montage de Google Drive ---\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/esg_rating_project\"\n",
        "\n",
        "# C) Créer l'arborescence\n",
        "print(\"\\n--- Création de l'arborescence du projet ---\")\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/esg_rating_project\"\n",
        "!mkdir -p \"{PROJECT_ROOT}/src\"\n",
        "!mkdir -p \"{PROJECT_ROOT}/data/reports_to_analyze\"\n",
        "!mkdir -p \"{PROJECT_ROOT}/rating_module\"\n",
        "\n",
        "print(\"\\n\\n✅ --- ENVIRONNEMENT DE PROJET PRÊT --- ✅\")\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/esg_rating_project\"\n"
      ],
      "metadata": {
        "id": "aCu6drXpe6Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KPI_Config.py"
      ],
      "metadata": {
        "id": "HVVtxpUakhW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fichier setup.py ---\n",
        "%%writefile {PROJECT_ROOT}/setup.py\n",
        "from setuptools import setup, find_packages\n",
        "setup(\n",
        "    name='esg_rating_engine',\n",
        "    version='0.9.0',\n",
        "    packages=find_packages(),\n",
        ")"
      ],
      "metadata": {
        "id": "fVzZ0S_b3diY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/esg_rating_project/src/kpi_config.py\n",
        "\n",
        "# ==============================================================================\n",
        "#  MATRICE DE PONDÉRATION SECTORIELLE (%)\n",
        "# ==============================================================================\n",
        "# Inspiré de votre image. Chaque clé est un secteur d'activité.\n",
        "# Les valeurs correspondent aux poids des piliers E, S, G pour ce secteur.\n",
        "# Le moteur essaiera de faire correspondre le secteur détecté à l'une de ces clés.\n",
        "# ==============================================================================\n",
        "#  SECTOR LIST (no weights)\n",
        "# ==============================================================================\n",
        "SECTOR_LIST = [\n",
        "    \"automobile\",\n",
        "    \"capital goods\",\n",
        "    \"materials\",\n",
        "    \"real estate\",\n",
        "    \"construction and engineering\",\n",
        "    \"food, beverages and agriculture\",\n",
        "    \"consumer goods\",\n",
        "    \"leisure\",\n",
        "    \"healthcare\",\n",
        "    \"retail\",\n",
        "    \"professional and commercial services\",\n",
        "    \"transport and logistics\",\n",
        "    \"media and telecommunications\",\n",
        "    \"energy and utilities\",\n",
        "    \"software\",\n",
        "    \"hardware\",\n",
        "    \"municipalities\",\n",
        "    \"financial services\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "#  CADRE DES INDICATEURS CLÉS DE PERFORMANCE (KPIs)\n",
        "# ==============================================================================\n",
        "# Ne contient plus les pondérations, seulement les questions et la direction.\n",
        "# La pondération sera appliquée à la fin, après le scoring.\n",
        "KPI_FRAMEWORK = {\n",
        "    'E': {\n",
        "        'scope_1_emissions': {\n",
        "            'question': (\n",
        "                \"Provide the 'Group total Scope 1 GHG emissions' for the most recent reporting year ONLY, unit must be tco2e or ktco2e \"\n",
        "                \"and note the unit and the latest year in the reasoning\"\n",
        "            ),\n",
        "            \"search_query\": \"Group total Scope 1 GHG emissions tCO2e ktCO2e latest year\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'Scope 1 emissions', 'direct emissions', 'GHG', 'carbon footprint',\n",
        "                'climate change', 'environmental impact', 'CO2', 'sustainability reporting'\n",
        "            ]\n",
        "        },\n",
        "        'scope_2_market': {\n",
        "            'question': (\n",
        "                \"Provide the 'Group total Scope 2 GHG emissions (location based)' for the most recent reporting year ONLY, unit must be tco2e or ktco2e \"\n",
        "                \"and note the unit and the latest year in the reasoning\"\n",
        "            ),\n",
        "            \"search_query\": \"Group total Scope 2 GHG emissions (location based) tCO2e ktCO2e latest year\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'Scope 2 emissions', 'indirect emissions', 'energy consumption',\n",
        "                'market-based emissions', 'GHG', 'carbon accounting', 'sustainability'\n",
        "            ]\n",
        "        },\n",
        "        'scope_3_emissions': {\n",
        "            'question': (\n",
        "                \"Provide the 'Group total Scope 3 GHG emissions' for the most recent reporting year ONLY, unit must be tco2e or ktco2e \"\n",
        "                \"and note the unit and the latest year in the reasoning\"\n",
        "            ),\n",
        "            \"search_query\": \"Group total Scope 3 GHG emissions tCO2e ktCO2e latest year\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'Scope 3 emissions', 'value chain emissions', 'indirect GHG',\n",
        "                'supply chain', 'carbon footprint', 'upstream emissions', 'downstream emissions'\n",
        "            ]\n",
        "        },\n",
        "        'renewable_energy_pct': {\n",
        "            'question': (\n",
        "                \"Provide the 'Renewable energy consumption percentage' for the most recent reporting year ONLY, unit must be kWh or kMWh or GWh\"\n",
        "                \"And note the unit in the reasoning.\"\n",
        "            ),\n",
        "            \"search_query\": \"renewable energy consumption share % latest year renewable electricity\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': [\n",
        "                'renewable energy', 'clean energy', 'energy production',\n",
        "                'solar', 'wind', 'hydro', 'green electricity', 'sustainable energy'\n",
        "            ]\n",
        "        },\n",
        "        'hazardous_waste': {\n",
        "            'question': (\n",
        "                \"Provide the 'TOTAL HAZARDOUS WASTE' for the most recent reporting year ONLY, in tonnes (t). \"\n",
        "                \"If—and only if—the latest-year figure is explicitly reported in kilograms (kg) or kilotonnes (kt), \"\n",
        "                \"safely convert to tonnes ( t = kg ÷ 1,000; t = kt × 1,000). If reported in 'tons', convert only if the \"\n",
        "                \"document explicitly states 'metric tons' (i.e., tonnes). If units are ambiguous, do not convert; \"\n",
        "                \"return the number as-is and note the unit in the reasoning.\"\n",
        "            ),\n",
        "            \"search_query\": \"total hazardous waste generated tonnes t latest year\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'waste generation', 'solid waste', 'hazardous waste',\n",
        "                'waste management', 'recycling', 'landfill', 'environmental footprint'\n",
        "            ]\n",
        "        },\n",
        "        'water_fresh_consumption': {\n",
        "            'question': (\n",
        "                \"Provide the total water consumed or abstracted for the most recent reporting year ONLY, in cubic \"\n",
        "                \"meters (m3). If—and only if—the latest-year value is explicitly reported in thousand m3 or million m3, \"\n",
        "                \"safely convert to m3 (m3 = thousand m3 × 1,000; m3 = million m3 × 1,000,000). If units are ambiguous, do not convert; \"\n",
        "                \"return the number as-is and note the unit in the reasoning.\"\n",
        "            ),\n",
        "            \"search_query\": \"total water withdrawn or consumed m3 latest year thousand m3 million m3\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'water usage', 'water abstraction', 'resource consumption',\n",
        "                'water footprint', 'sustainable water use', 'environmental impact'\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    'S': {\n",
        "        'employee_turnover_rate': {\n",
        "            'question': (\n",
        "                \"Provide the 'Employee turnover rate' for the most recent reporting year ONLY, in percent (%).\"\n",
        "            ),\n",
        "            \"search_query\": \"employee turnover rate % latest year attrition staff turnover\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'employee turnover', 'HR metrics', 'workforce stability',\n",
        "                'retention rate', 'human capital', 'employee engagement'\n",
        "            ]\n",
        "        },\n",
        "        'trir': {\n",
        "            'question': (\n",
        "                \"Provide the 'Accident Rate' for the most recent reporting year ONLY, \"\n",
        "                \"per 1,000,000 hours worked, it can also be called loss frequency, accident frequency or incident rate extract the rate as stated and note the unit and the latest year in the reasoning\"\n",
        "            ),\n",
        "            \"search_query\": \"accident frequency rate per 1,000,000 hours latest year TRIR AFR loss frequency\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'TRIR', 'occupational safety', 'incident rate',\n",
        "                'workplace injuries', 'health and safety', 'employee wellbeing'\n",
        "            ]\n",
        "        },\n",
        "        'health_safety_fatalities': {\n",
        "            'question': (\n",
        "                \"Provide the number of work-related 'Fatalities' for the most recent reporting year ONLY.\"\n",
        "            ),\n",
        "            \"search_query\":\"work-related fatalities employees contractors total latest year\",\n",
        "            'direction': 'lower_is_better',\n",
        "            'keywords': [\n",
        "                'workplace fatalities', 'occupational hazards', 'employee safety',\n",
        "                'fatal incidents', 'health and safety', 'risk management'\n",
        "            ]\n",
        "        },\n",
        "        'women_exec_mgmt': {\n",
        "            'question': (\n",
        "                \"Provide the percentage (%) of 'female in the executiv management' for the most recent reporting year ONLY.\"\n",
        "            ),\n",
        "            \"search_query\":\"women in executiv management % female employees share latest year\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': [\n",
        "                'gender diversity', 'female workforce', 'inclusion',\n",
        "                'equality', 'diversity metrics', 'HR reporting'\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    'G': {\n",
        "        'female_directors_pct': {\n",
        "            'question': (\n",
        "                \"Provide the percentage (%) of 'Women in the Board of Directors.' for the most recent reporting year ONLY.\"\n",
        "            ),\n",
        "            \"search_query\":\"women in executive committee % latest year female representation ExCom\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': [\n",
        "                'board diversity', 'female representation', 'gender equality',\n",
        "                'governance', 'leadership diversity', 'corporate board'\n",
        "            ]\n",
        "        },\n",
        "        'board_independence_pct': {\n",
        "            'question': (\n",
        "                \"Provide the percentage of independent directors on the board for the most recent reporting year ONLY.\"\n",
        "            ),\n",
        "            \"search_query\": \"independent directors % of board latest year board independence\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': [\n",
        "                'board independence', 'corporate governance', 'transparency',\n",
        "                'accountability', 'board structure', 'non-executive directors'\n",
        "            ]\n",
        "        },\n",
        "        'training_hours_per_emp': {\n",
        "            'question': (\n",
        "                \"Provide the average number of training hours provided per employee for the \"\n",
        "                \"most recent reporting year ONLY.\"\n",
        "            ),\n",
        "            \"search_query\":\"average training hours per employee\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': [\n",
        "                'ethics training', 'code of conduct', 'compliance',\n",
        "                'employee integrity', 'corporate ethics', 'training programs'\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    'C': {\n",
        "        'env_controversy_score': {\n",
        "            'question': \"Report the company's ENVIRONMENT CONTROVERSIES score at the section level\",\n",
        "            \"search_query\":\"ENVIRONMENT CONTROVERSIES score\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': ['ENVIRONMENT CONTROVERSIES'\n",
        "            ]\n",
        "        },\n",
        "        'customers_controversy_score': {\n",
        "            'question': \"Report the company's CUSTOMERS CONTROVERSIES score, a sub-section of the social section\",\n",
        "            \"search_query\":\"CUSTOMERS CONTROVERSIES score social\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': ['CUSTOMERS CONTROVERSIES'\n",
        "            ]\n",
        "        },\n",
        "        'human_rights_community_controversy_score': {\n",
        "            'question': \"Report the company's HUMAN RIGHTS and COMMUNITY CONTROVERSIES score, a sub-section of the social section\",\n",
        "            \"search_query\":\"HUMAN RIGHTS & COMMUNITY CONTROVERSIES\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': ['HUMAN RIGHTS', 'COMMUNITY CONTROVERSIES'\n",
        "            ]\n",
        "        },\n",
        "        'labor_rights_supply_chain_controversy_score': {\n",
        "            'question': \"Report the company's LABOR RIGHTS and SUPPLY CHAIN CONTROVERSIES score, a sub-section of the social section\",\n",
        "            \"search_query\":\"LABOR RIGHTS & SUPPLY CHAIN CONTROVERSIES\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': ['LABOR RIGHTS', 'SUPPLY CHAIN CONTROVERSIES'\n",
        "            ]\n",
        "        },\n",
        "        'governance_controversy_score': {\n",
        "            'question': \"Report the company's GOVERNANCE CONTROVERSIES score at the section level\",\n",
        "            \"search_query\":\"GOVERNANCE CONTROVERSIES score\",\n",
        "            'direction': 'higher_is_better',\n",
        "            'keywords': ['GOVERNANCE CONTROVERSIES'\n",
        "            ]\n",
        "        }\n",
        "      }\n",
        "    }"
      ],
      "metadata": {
        "id": "sA7THfnCn-1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "c6Orc86IkvzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {PROJECT_ROOT}/src/utils.py\n",
        "# src/utils.py\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# spaCy est optionnel (fallback regex si indisponible)\n",
        "try:\n",
        "    import spacy\n",
        "    try:\n",
        "        NLP = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "    except Exception:\n",
        "        NLP = None\n",
        "except Exception:\n",
        "    NLP = None\n",
        "\n",
        "def clean_text_spacy(text: str, remove_stopwords: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Nettoie le texte. Utilise spaCy si dispo; sinon fallback regex.\n",
        "    Optimisé pour la préparation des embeddings.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # Nettoyage grossier\n",
        "    t = re.sub(r'https?://\\\\S+|www\\\\.\\\\S+', '', text)              # URLs\n",
        "    t = re.sub(r'\\\\S+@\\\\S+', '', t)                                # Emails\n",
        "    t = re.sub(r'\\\\b(Page\\\\s\\\\d+\\\\s*(of\\\\s\\\\d+)?)\\\\b', '', t, flags=re.IGNORECASE)\n",
        "\n",
        "    if NLP is None:\n",
        "        # Fallback léger (sans spaCy)\n",
        "        t = re.sub(r'[^A-Za-z0-9%.,:;()\\\\-\\\\s]', ' ', t)\n",
        "        t = re.sub(r'\\\\s+', ' ', t).strip()\n",
        "        return t.lower()\n",
        "\n",
        "    # spaCy path\n",
        "    doc = NLP(t)\n",
        "    toks = []\n",
        "    for tok in doc:\n",
        "        if tok.is_space or tok.is_punct:\n",
        "            continue\n",
        "        if len(tok.text) == 1 and not tok.text.isdigit():\n",
        "            continue\n",
        "        if remove_stopwords and tok.is_stop:\n",
        "            continue\n",
        "        toks.append(tok.text.lower())\n",
        "    cleaned = \" \".join(toks)\n",
        "    cleaned = re.sub(r'\\\\s+', ' ', cleaned).strip()\n",
        "    return cleaned\n",
        "\n",
        "def linearize_table(table: pd.DataFrame, source_page: int) -> list[str]:\n",
        "    \"\"\"\n",
        "    Transforme un DataFrame en phrases sémantiques (pour l'index texte).\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    if table is None or table.empty or table.columns.empty:\n",
        "        return sentences\n",
        "\n",
        "    headers = [str(h).replace('\\\\n', ' ').strip() for h in table.columns]\n",
        "    for _, row in table.iterrows():\n",
        "        try:\n",
        "            row_data = [str(item).replace('\\\\n', ' ').strip() for item in row]\n",
        "            subject = row_data[0] if row_data else \"\"\n",
        "            if not subject:\n",
        "                continue\n",
        "            sentence = f\"From a table on page {source_page} regarding '{subject}':\"\n",
        "            has_data = False\n",
        "            for i in range(1, len(row_data)):\n",
        "                if i < len(headers) and row_data[i] and headers[i]:\n",
        "                    sentence += f\" the value for '{headers[i]}' is '{row_data[i]}';\"\n",
        "                    has_data = True\n",
        "            if has_data:\n",
        "                sentences.append(sentence)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "46u6qU7wki5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PerfectTables"
      ],
      "metadata": {
        "id": "d-4P-4ISNnIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {PROJECT_ROOT}/src/perfect_tables.py\n",
        "import os\n",
        "import io\n",
        "import math\n",
        "import hashlib\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, TableTransformerForObjectDetection\n",
        "\n",
        "# -------------------------\n",
        "# Config par défaut (Kaggle)\n",
        "# -------------------------\n",
        "DEFAULT_IMG_DPI = 288  # ~4x @72dpi, bon compromis qualité/mémoire\n",
        "DET_MODEL = \"microsoft/table-transformer-detection\"\n",
        "STR_MODEL = \"microsoft/table-transformer-structure-recognition\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CellUnit:\n",
        "    row: int\n",
        "    col: int\n",
        "    text: str\n",
        "    bbox: List[float]  # [x0,y0,x1,y1] en pixels (coords du crop d'image)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TableUnit:\n",
        "    page: int\n",
        "    bbox: List[float]            # bbox table en pixels (coord. image page)\n",
        "    bbox_page_pts: List[float]   # bbox table en points PDF (rect page)\n",
        "    fingerprint: str\n",
        "    df: Any                      # pandas.DataFrame\n",
        "    cells: List[CellUnit]\n",
        "    image_crop_path: str\n",
        "    doc_type: str\n",
        "    text_repr: str               # headers | first_col preview\n",
        "\n",
        "\n",
        "def _render_page_to_image(doc, page_idx: int, dpi: int = DEFAULT_IMG_DPI) -> Image.Image:\n",
        "    page = doc.load_page(page_idx)\n",
        "    zoom = dpi / 72.0\n",
        "    mat = fitz.Matrix(zoom, zoom)\n",
        "    pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "    img = Image.frombytes(\"RGB\", (pix.width, pix.height), pix.samples)\n",
        "    return img\n",
        "\n",
        "\n",
        "def _words_as_pixels(page, img_w: int, img_h: int, dpi: int) -> List[Tuple[float,float,float,float,str]]:\n",
        "    # PyMuPDF words: (x0,y0,x1,y1,\"text\", block_no, line_no, word_no) in POINTS (72dpi)\n",
        "    words = page.get_text(\"words\")\n",
        "    page_rect = page.rect\n",
        "    sx = (dpi / 72.0)\n",
        "    sy = (dpi / 72.0)\n",
        "    shift_x, shift_y = -page_rect.x0, -page_rect.y0\n",
        "\n",
        "    px_words = []\n",
        "    for (x0, y0, x1, y1, txt, *_rest) in words:\n",
        "        X0 = (x0 + shift_x) * sx\n",
        "        Y0 = (y0 + shift_y) * sy\n",
        "        X1 = (x1 + shift_x) * sx\n",
        "        Y1 = (y1 + shift_y) * sy\n",
        "        # clamp\n",
        "        X0 = max(0, min(img_w - 1, X0)); X1 = max(0, min(img_w - 1, X1))\n",
        "        Y0 = max(0, min(img_h - 1, Y0)); Y1 = max(0, min(img_h - 1, Y1))\n",
        "        px_words.append((X0, Y0, X1, Y1, txt))\n",
        "    return px_words\n",
        "\n",
        "\n",
        "def _detect_tables(image: Image.Image, processor, model, score_thresh=0.5):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.inference_mode():\n",
        "        out = model(**inputs)\n",
        "    target_sizes = torch.tensor([image.size[::-1]]).to(DEVICE)  # (h, w)\n",
        "    results = processor.post_process_object_detection(out, target_sizes=target_sizes)[0]\n",
        "    bboxes, scores, labels = results[\"boxes\"].cpu().numpy(), results[\"scores\"].cpu().numpy(), results[\"labels\"].cpu().numpy()\n",
        "    keep = [i for i, (s, l) in enumerate(zip(scores, labels)) if s >= score_thresh and int(l) == 0]  # label 1 == \"table\"\n",
        "    return bboxes[keep], scores[keep]\n",
        "\n",
        "\n",
        "def _structure_on_crop(crop_img: Image.Image, str_processor, str_model, score_thresh=0.4):\n",
        "    inputs = str_processor(images=crop_img, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.inference_mode():\n",
        "        out = str_model(**inputs)\n",
        "    target_sizes = torch.tensor([crop_img.size[::-1]]).to(DEVICE)\n",
        "    results = str_processor.post_process_object_detection(out, target_sizes=target_sizes)[0]\n",
        "    boxes, scores, labels = results[\"boxes\"].cpu().numpy(), results[\"scores\"].cpu().numpy(), results[\"labels\"].cpu().numpy()\n",
        "    # labels mapping (from model card)\n",
        "    # 0: table, 1: table column, 2: table row, 3: table column header, 4: table projected row header,\n",
        "    # 5: table spanning cell, 6: no object\n",
        "    rows = [boxes[i] for i in range(len(labels)) if scores[i] >= score_thresh and int(labels[i]) == 2]\n",
        "    cols = [boxes[i] for i in range(len(labels)) if scores[i] >= score_thresh and int(labels[i]) == 1]\n",
        "    return rows, cols\n",
        "\n",
        "\n",
        "def _intersect(a, b):\n",
        "    x0 = max(a[0], b[0]); y0 = max(a[1], b[1])\n",
        "    x1 = min(a[2], b[2]); y1 = min(a[3], b[3])\n",
        "    if x1 <= x0 or y1 <= y0:\n",
        "        return None\n",
        "    return [x0, y0, x1, y1]\n",
        "\n",
        "\n",
        "def _assign_text_to_grid(crop_words, row_boxes, col_boxes) -> Tuple[pd.DataFrame, List[CellUnit]]:\n",
        "    # trier lignes/colonnes (centre géometrique)\n",
        "    rows = sorted(row_boxes, key=lambda b: (b[1]+b[3])/2.0)\n",
        "    cols = sorted(col_boxes, key=lambda b: (b[0]+b[2])/2.0)\n",
        "    if not rows or not cols:\n",
        "        # fallback: tout le texte en une cellule\n",
        "        text = \" \".join([w[4] for w in sorted(crop_words, key=lambda t: (t[1], t[0]))])\n",
        "        df = pd.DataFrame([[text]], columns=[\"Value\"])\n",
        "        cells = [CellUnit(0,0,text,[0,0,1,1])]\n",
        "        return df, cells\n",
        "\n",
        "    # grille via intersections\n",
        "    H, W = len(rows), len(cols)\n",
        "    grid: List[List[str]] = [[ \"\" for _ in range(W)] for __ in range(H)]\n",
        "    cell_boxes: List[List[List[float]]] = [[ None for _ in range(W)] for __ in range(H)]\n",
        "\n",
        "    for i, rb in enumerate(rows):\n",
        "        for j, cb in enumerate(cols):\n",
        "            inter = _intersect(rb, cb)\n",
        "            if inter is None:\n",
        "                # petite extension tolérante\n",
        "                eps = 2.0\n",
        "                inter = _intersect([rb[0], rb[1]-eps, rb[2], rb[3]+eps], [cb[0]-eps, cb[1], cb[2]+eps, cb[3]])\n",
        "            if inter is None:\n",
        "                inter = [ (rb[0]+cb[0])/2, (rb[1]+cb[1])/2, (rb[2]+cb[2])/2, (rb[3]+cb[3])/2 ]\n",
        "            cell_boxes[i][j] = inter\n",
        "\n",
        "    # affecter tokens à la cellule la plus proche par centre\n",
        "    for (x0,y0,x1,y1,txt) in crop_words:\n",
        "        cx, cy = (x0+x1)/2.0, (y0+y1)/2.0\n",
        "        best = None\n",
        "        for i in range(H):\n",
        "            for j in range(W):\n",
        "                b = cell_boxes[i][j]\n",
        "                if b[0] <= cx <= b[2] and b[1] <= cy <= b[3]:\n",
        "                    best = (i,j); break\n",
        "            if best: break\n",
        "        if best is None:\n",
        "            # chercher cellule la plus proche (distance centre->box)\n",
        "            dmin, pos = 1e18, (0,0)\n",
        "            for i in range(H):\n",
        "                for j in range(W):\n",
        "                    b = cell_boxes[i][j]\n",
        "                    bx, by = (b[0]+b[2])/2.0, (b[1]+b[3])/2.0\n",
        "                    d = (bx-cx)**2 + (by-cy)**2\n",
        "                    if d < dmin: dmin, pos = d, (i,j)\n",
        "            best = pos\n",
        "        i, j = best\n",
        "        if grid[i][j]:\n",
        "            grid[i][j] += \" \" + txt\n",
        "        else:\n",
        "            grid[i][j] = txt\n",
        "\n",
        "    # construire DataFrame (première ligne = header si non numérique)\n",
        "    headers = []\n",
        "    first_row = grid[0]\n",
        "    if any([any(ch.isalpha() for ch in (c or \"\")) for c in first_row]):\n",
        "        headers = [c if c else f\"Col{j+1}\" for j,c in enumerate(first_row)]\n",
        "        data_rows = grid[1:] if len(grid) > 1 else []\n",
        "    else:\n",
        "        headers = [f\"Col{j+1}\" for j in range(len(first_row))]\n",
        "        data_rows = grid\n",
        "\n",
        "    df = pd.DataFrame(data_rows, columns=headers)\n",
        "    cells_out: List[CellUnit] = []\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            t = grid[i][j] if i < len(grid) and j < len(grid[i]) else \"\"\n",
        "            cells_out.append(CellUnit(i, j, t, [float(x) for x in cell_boxes[i][j]]))\n",
        "    return df, cells_out\n",
        "\n",
        "\n",
        "def _fingerprint_df(df: pd.DataFrame) -> str:\n",
        "    try:\n",
        "        header = \" | \".join([str(c) for c in df.columns])\n",
        "        first_col = \"\"\n",
        "        if df.shape[1] > 0:\n",
        "            first_col = \" | \".join([str(x) for x in df.iloc[:10, 0].astype(str).tolist()])\n",
        "        shape = f\"{df.shape[0]}x{df.shape[1]}\"\n",
        "        raw = f\"{header} || {first_col} || {shape}\".lower()\n",
        "        raw = \"\".join(ch if ch.isalnum() or ch in \" %|\" else \" \" for ch in raw)\n",
        "        raw = \" \".join(raw.split())\n",
        "        return hashlib.sha1(raw.encode(\"utf-8\")).hexdigest()\n",
        "    except Exception:\n",
        "        return hashlib.sha1(str(id(df)).encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "\n",
        "def extract_tables_from_pdf(\n",
        "    pdf_path: str,\n",
        "    out_img_dir: str,\n",
        "    doc_type: str,\n",
        "    dpi: int = DEFAULT_IMG_DPI,\n",
        "    det_thresh: float = 0.8,\n",
        "    str_thresh: float = 0.7\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Renvoie une liste de TableUnit (dict) pour alimenter LayoutLMv3 et l'index.\n",
        "    \"\"\"\n",
        "    processor_det = AutoImageProcessor.from_pretrained(DET_MODEL)\n",
        "    model_det = TableTransformerForObjectDetection.from_pretrained(DET_MODEL).to(DEVICE)\n",
        "    processor_str = AutoImageProcessor.from_pretrained(STR_MODEL)\n",
        "    model_str = TableTransformerForObjectDetection.from_pretrained(STR_MODEL).to(DEVICE)\n",
        "\n",
        "    out: List[Dict[str, Any]] = []\n",
        "\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for p in range(len(doc)):\n",
        "            page = doc.load_page(p)\n",
        "            img = _render_page_to_image(doc, p, dpi=dpi)\n",
        "            W, H = img.size\n",
        "            px_words = _words_as_pixels(page, W, H, dpi=dpi)\n",
        "\n",
        "            # détection table(s) -> bboxes image pixels\n",
        "            tb_boxes, tb_scores = _detect_tables(img, processor_det, model_det, score_thresh=det_thresh)\n",
        "            if len(tb_boxes) == 0:\n",
        "                continue\n",
        "\n",
        "            for t_idx, box in enumerate(tb_boxes):\n",
        "                x0, y0, x1, y1 = [float(v) for v in box]\n",
        "                x0c, y0c = max(0, x0), max(0, y0)\n",
        "                x1c, y1c = min(W-1, x1), min(H-1, y1)\n",
        "\n",
        "                # crop + mots dans la zone\n",
        "                crop = img.crop((x0c, y0c, x1c, y1c))\n",
        "                cW, cH = crop.size\n",
        "                crop_words = []\n",
        "                for (wx0, wy0, wx1, wy1, wtxt) in px_words:\n",
        "                    if wx1 < x0c or wx0 > x1c or wy1 < y0c or wy0 > y1c:\n",
        "                        continue\n",
        "                    # clamp au crop\n",
        "                    cx0 = max(0, wx0 - x0c); cy0 = max(0, wy0 - y0c)\n",
        "                    cx1 = min(cW-1, wx1 - x0c); cy1 = min(cH-1, wy1 - y0c)\n",
        "                    if cx1 > cx0 and cy1 > cy0:\n",
        "                        crop_words.append((cx0, cy0, cx1, cy1, wtxt))\n",
        "\n",
        "                # structure (rows/cols)\n",
        "                row_boxes, col_boxes = _structure_on_crop(crop, processor_str, model_str, score_thresh=str_thresh)\n",
        "                df, cells = _assign_text_to_grid(crop_words, row_boxes, col_boxes)\n",
        "\n",
        "                # sauvegarder image pour explicabilité / LayoutLM\n",
        "                os.makedirs(out_img_dir, exist_ok=True)\n",
        "                img_name = os.path.join(out_img_dir, f\"{os.path.basename(pdf_path)}_p{p+1}_t{t_idx+1}.png\")\n",
        "                crop.save(img_name)\n",
        "\n",
        "                # bbox page (points PDF) pour traçabilité\n",
        "                page_rect = page.rect\n",
        "                sx = (dpi / 72.0); sy = (dpi / 72.0)\n",
        "                page_bbox = [\n",
        "                    (x0c / sx) + page_rect.x0,\n",
        "                    (y0c / sy) + page_rect.y0,\n",
        "                    (x1c / sx) + page_rect.x0,\n",
        "                    (y1c / sy) + page_rect.y0,\n",
        "                ]\n",
        "\n",
        "                fp = _fingerprint_df(df)\n",
        "                headers = \" | \".join(map(str, list(df.columns)))\n",
        "                fcol = \" | \".join(map(str, list(df.iloc[:,0].astype(str).values[:10]))) if df.shape[1] > 0 else \"\"\n",
        "                text_repr = f\"Table: {headers} || first_col: {fcol}\"\n",
        "\n",
        "                out.append({\n",
        "                    \"page\": int(p+1),\n",
        "                    \"bbox\": [x0c, y0c, x1c, y1c],\n",
        "                    \"bbox_page_pts\": [float(v) for v in page_bbox],\n",
        "                    \"fingerprint\": fp,\n",
        "                    \"df\": df,\n",
        "                    \"cells\": [asdict(c) for c in cells],\n",
        "                    \"image_crop_path\": img_name,\n",
        "                    \"doc_type\": doc_type,\n",
        "                    \"text\": text_repr,\n",
        "                })\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "Pz3rPjRyxt3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction Engine"
      ],
      "metadata": {
        "id": "Z3O6JoP6dd4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {PROJECT_ROOT}/src/esg_engine.py\n",
        "\n",
        "#==============================================================================\n",
        "#FILE: src/esg_engine.py (PyMuPDF + PerfectTables, Donut DocVQA + RAG, BGE rerank, Judge, cache+CSV)\n",
        "#==============================================================================\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import faiss\n",
        "import spacy\n",
        "import fitz\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import concurrent.futures as cf\n",
        "\n",
        "from PIL import Image\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "\n",
        "from transformers import (\n",
        "AutoTokenizer,\n",
        "AutoModelForCausalLM,\n",
        "BitsAndBytesConfig,\n",
        "DonutProcessor,\n",
        "AutoModelForVision2Seq,\n",
        "VisionEncoderDecoderModel\n",
        ")\n",
        "\n",
        "#--- Projet local ---\n",
        "\n",
        "from src.kpi_config import KPI_FRAMEWORK, SECTOR_LIST\n",
        "from src.utils import clean_text_spacy, linearize_table\n",
        "from src.perfect_tables import extract_tables_from_pdf\n",
        "\n",
        "CSV_DELIM = \";\"\n",
        "CAND_SCHEMA_VERSION = \"v2\"\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "#Helpers de nettoyage si spaCy indispo\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "def _clean_fallback(txt: str) -> str:\n",
        "    txt = (txt or \"\").replace(\"\\u00A0\",\" \").replace(\"\\u2009\",\" \").replace(\"\\u202F\",\" \")\n",
        "    txt = re.sub(r\"[ \\t]+\", \" \", txt)\n",
        "    txt = re.sub(r\"\\s{2,}\", \" \", txt)\n",
        "    return txt.strip()\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "#Classe principale\n",
        "#--------------------------------------------------------------------------\n",
        "\n",
        "class ESGRatingEngine:\n",
        "    def __init__(self, use_fine_tuned_model: bool = False):\n",
        "        \"\"\"\n",
        "        Qwen2-7B (4-bit quand CUDA), Qwen3-Embedding (CPU), BGE CrossEncoder (CPU),\n",
        "        RAG Hybride + Donut DocVQA + Judge.\n",
        "        \"\"\"\n",
        "        os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "        os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
        "\n",
        "        self.device = \"cuda\" if (hasattr(torch, \"cuda\") and torch.cuda.is_available()) else \"cpu\"\n",
        "        if self.device == \"cuda\":\n",
        "            try:\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception:\n",
        "                pass\n",
        "        print(\"--- Initializing ESG Rating Engine (VRAM-safe) ---\")\n",
        "\n",
        "        # --- Model names ---\n",
        "        model_name = \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"\n",
        "        embedding_model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "\n",
        "        # --- LLM (Qwen2) ---\n",
        "        print(f\"Loading LLM: {model_name}\")\n",
        "        use_4bit = torch.cuda.is_available()\n",
        "        if use_4bit:\n",
        "            bnb_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "            )\n",
        "            max_memory = {\"cpu\": \"48GiB\"}\n",
        "            try:\n",
        "                total_gb = int(torch.cuda.get_device_properties(0).total_memory / (1024**3))\n",
        "                cap = max(10, total_gb - 3)  # garde ~3 GiB de marge\n",
        "                max_memory[0] = f\"{cap}GiB\"\n",
        "            except Exception:\n",
        "                max_memory[0] = \"19GiB\"\n",
        "            llm_kwargs = dict(\n",
        "                device_map=\"auto\",\n",
        "                quantization_config=bnb_config,\n",
        "                torch_dtype=torch.float16,\n",
        "                max_memory=max_memory,\n",
        "                low_cpu_mem_usage=True,\n",
        "                trust_remote_code=True,\n",
        "            )\n",
        "        else:\n",
        "            llm_kwargs = dict(\n",
        "                device_map=\"cpu\",\n",
        "                torch_dtype=torch.float32,\n",
        "                low_cpu_mem_usage=True,\n",
        "                trust_remote_code=True,\n",
        "            )\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "        # ✅ Forcer ChatML si absent/incorrect\n",
        "        if (self.tokenizer.chat_template is None) or (\"<|im_start|>\" not in str(self.tokenizer.chat_template)):\n",
        "            self.tokenizer.chat_template = (\n",
        "                \"{% for message in messages %}\"\n",
        "                \"{% if message['role'] == 'system' %}\"\n",
        "                \"<|im_start|>system\\n{{ message['content'] }}<|im_end|>\\n\"\n",
        "                \"{% elif message['role'] == 'user' %}\"\n",
        "                \"<|im_start|>user\\n{{ message['content'] }}<|im_end|>\\n\"\n",
        "                \"{% elif message['role'] == 'assistant' %}\"\n",
        "                \"<|im_start|>assistant\\n{{ message['content'] }}<|im_end|>\\n\"\n",
        "                \"{% endif %}\"\n",
        "                \"{% endfor %}\"\n",
        "                \"{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"\n",
        "            )\n",
        "\n",
        "        # ✅ Aligner EOS/PAD sur le token ChatML de fin\n",
        "        im_end_id = self.tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
        "        if im_end_id is not None and im_end_id != -1:\n",
        "            self.tokenizer.eos_token_id = im_end_id\n",
        "            self.tokenizer.eos_token    = \"<|im_end|>\"\n",
        "            if self.tokenizer.pad_token_id is None:\n",
        "                self.tokenizer.pad_token_id = im_end_id\n",
        "                self.tokenizer.pad_token    = \"<|im_end|>\"\n",
        "\n",
        "\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name, **llm_kwargs)\n",
        "\n",
        "        # --- Embeddings (CPU) ---\n",
        "        print(f\"\\nLoading embedding model on CPU: {embedding_model_name}\")\n",
        "        self.embedding_model = SentenceTransformer(\n",
        "            embedding_model_name,\n",
        "            device=\"cpu\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        self.embedding_dim = self.embedding_model.get_sentence_embedding_dimension()\n",
        "        self.embedding_batch_size = 16  # batch réduit (RAM)\n",
        "\n",
        "        # --- Cross-encoder reranker (CPU, base) ---\n",
        "        self.reranker_name = \"BAAI/bge-reranker-v2-m3\"\n",
        "        try:\n",
        "            print(f\"\\nLoading cross-encoder reranker on CPU: {self.reranker_name}\")\n",
        "            self.reranker = CrossEncoder(self.reranker_name, device=\"cpu\")\n",
        "        except Exception as e:\n",
        "            print(f\"  -> WARNING: {self.reranker_name} unavailable ({e}). Falling back to MiniLM.\")\n",
        "            self.reranker_name = \"cross-encoder/ms-marco-MiniLM-L-2-v2\"\n",
        "            self.reranker = CrossEncoder(self.reranker_name, device=\"cpu\")\n",
        "\n",
        "        # --- Donut DocVQA ---\n",
        "        self.enable_donut = os.environ.get(\"ESG_ENABLE_DONUT\", \"1\") == \"1\"\n",
        "        self.donut_model_name = os.environ.get(\n",
        "            \"ESG_DONUT_MODEL\",\n",
        "            \"naver-clova-ix/donut-base-finetuned-docvqa\"\n",
        "        )\n",
        "        self.donut_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.max_donut_new_tokens = int(os.environ.get(\"ESG_DONUT_MAX_NEW_TOKENS\", \"48\"))\n",
        "        self.donut_proc = None\n",
        "        self.donut_model = None\n",
        "        # Nombre de tables testées par VQA (augmente la couverture)\n",
        "        self.table_llm_limit = int(os.environ.get(\"ESG_TABLE_LLM_LIMIT\", \"5\"))\n",
        "\n",
        "        # --- NLP + state ---\n",
        "        print(\"\\nLoading spaCy...\")\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except Exception:\n",
        "            self.nlp = None  # fallback regex si besoin\n",
        "\n",
        "        # Stores / state\n",
        "        self.chunks = []\n",
        "        self.chunk_doc_types = []\n",
        "        self.tables = []\n",
        "        self.all_embeddings = None\n",
        "        self.faiss_index = None\n",
        "        self.bm25_index = None\n",
        "        self.analysis_state = {}\n",
        "        self.page_texts = []\n",
        "\n",
        "        # RAG knobs\n",
        "        self.serialize_rows = 12\n",
        "        self.serialize_cols = 8\n",
        "        self.max_new_tokens_json = 512\n",
        "        self.rag_top_candidates = 24\n",
        "        self.rag_top_k_context = 3\n",
        "        self._last_rag_context = \"\"\n",
        "\n",
        "        try:\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        self.debug = False\n",
        "        self.debug_trace = {}\n",
        "        self.debug_tables = True\n",
        "\n",
        "        # --- Paths / cache ---\n",
        "        self.project_root = os.environ.get(\"ESG_PROJECT_ROOT\", os.path.abspath(os.getcwd()))\n",
        "        self.cache_dir     = os.environ.get(\"ESG_CACHE_DIR\", os.path.join(self.project_root, \"cache\"))\n",
        "        self.image_dir     = os.path.join(self.cache_dir, \"images\")\n",
        "        self.candidates_log_csv = os.environ.get(\n",
        "            \"ESG_CANDIDATES_CSV\",\n",
        "            os.path.join(self.project_root, \"data\", \"esg_kpi_candidates_log.csv\"),\n",
        "        )\n",
        "\n",
        "        # Crée les dossiers au démarrage\n",
        "        os.makedirs(self.cache_dir, exist_ok=True)\n",
        "        os.makedirs(self.image_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.dirname(self.candidates_log_csv), exist_ok=True)\n",
        "\n",
        "\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.ipc_collect()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Utils génériques\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _ensure_donut_ready(self) -> bool:\n",
        "        \"\"\"\n",
        "        Charge Donut DocVQA (processor+model) en lazy, correctement configuré.\n",
        "        - Conditioning sur image + prompt (géré au moment de generate).\n",
        "        \"\"\"\n",
        "        if not self.enable_donut:\n",
        "            return False\n",
        "\n",
        "        # Valeurs par défaut si pas déjà définies\n",
        "        if not getattr(self, \"donut_model_name\", None):\n",
        "            self.donut_model_name = os.environ.get(\n",
        "                \"ESG_DONUT_MODEL\",\n",
        "                \"naver-clova-ix/donut-base-finetuned-docvqa\"\n",
        "            )\n",
        "        if not getattr(self, \"donut_device\", None):\n",
        "            self.donut_device = \"cuda\" if (hasattr(torch, \"cuda\") and torch.cuda.is_available()) else \"cpu\"\n",
        "        if not getattr(self, \"max_donut_new_tokens\", None):\n",
        "            self.max_donut_new_tokens = int(os.environ.get(\"ESG_DONUT_MAX_NEW_TOKENS\", \"48\"))\n",
        "\n",
        "        if self.donut_proc is not None and self.donut_model is not None:\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            print(f\"Loading Donut DocVQA: {self.donut_model_name} on {self.donut_device}\")\n",
        "            self.donut_proc = DonutProcessor.from_pretrained(self.donut_model_name)\n",
        "            # VisionEncoderDecoderModel attendu pour Donut\n",
        "            self.donut_model = VisionEncoderDecoderModel.from_pretrained(self.donut_model_name)\n",
        "            self.donut_model = self.donut_model.to(self.donut_device)\n",
        "            self.donut_model.eval()\n",
        "            print(f\"Donut ready on {self.donut_device}: {self.donut_model_name}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: cannot load Donut ({e}). Disabling it.\")\n",
        "            self.enable_donut = False\n",
        "            self.donut_proc = None\n",
        "            self.donut_model = None\n",
        "            return False\n",
        "\n",
        "    def _find_df_context_phrase(self, df: pd.DataFrame, raw_answer: str | None, value: float | None, unit_hint: str | None) -> str:\n",
        "        \"\"\"\n",
        "        Recompose une phrase contextuelle à partir du DF du tableau :\n",
        "        - Tente d'identifier la cellule contenant la valeur extraite (en utilisant 'raw_answer' si dispo).\n",
        "        - Construit: 'row_label — col_header: cell_text'.\n",
        "        - Pas de fallback sur le nom du KPI (si rien trouvé -> retourne \"\").\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if df is None or df.empty:\n",
        "                return \"\"\n",
        "\n",
        "            # Normaliser DF en str\n",
        "            sdf = df.astype(str)\n",
        "\n",
        "            # Construit une liste de motifs plausibles à retrouver dans la cellule\n",
        "            import re\n",
        "            patterns: list[str] = []\n",
        "            if raw_answer:\n",
        "                # récupère tous les tokens numériques (avec % éventuel) du texte de Donut\n",
        "                toks = re.findall(r\"[0-9][0-9\\.,\\s]*%?\", raw_answer)\n",
        "                # nettoyer\n",
        "                toks = [t.strip() for t in toks if t and any(ch.isdigit() for ch in t)]\n",
        "                patterns.extend(toks)\n",
        "\n",
        "            # si on a une value numérique, générer quelques variantes textuelles possibles\n",
        "            if isinstance(value, (int, float)):\n",
        "                v = float(value)\n",
        "                # formes sans pourcentage\n",
        "                patterns.extend([\n",
        "                    f\"{int(v)}\" if abs(v - int(v)) < 1e-6 else f\"{v}\",\n",
        "                    f\"{int(v)}\",\n",
        "                    f\"{v:.1f}\",\n",
        "                    f\"{v:.2f}\",\n",
        "                    f\"{v:.3f}\",\n",
        "                ])\n",
        "                # si % suspecté, générer variantes\n",
        "                if unit_hint and \"%\" in unit_hint:\n",
        "                    base = f\"{int(v)}\" if abs(v - int(v)) < 1e-6 else f\"{v}\"\n",
        "                    patterns.extend([\n",
        "                        base + \"%\",\n",
        "                        base + \" %\",\n",
        "                        f\"{v:.1f}%\",\n",
        "                        f\"{v:.1f} %\",\n",
        "                        f\"{v:.2f}%\",\n",
        "                        f\"{v:.2f} %\",\n",
        "                    ])\n",
        "\n",
        "            # déduire aussi formes avec virgule\n",
        "            extended = []\n",
        "            for p in patterns:\n",
        "                if \".\" in p:\n",
        "                    extended.append(p.replace(\".\", \",\"))\n",
        "                if \",\" in p:\n",
        "                    extended.append(p.replace(\",\", \".\"))\n",
        "            patterns.extend(extended)\n",
        "\n",
        "            # cherche la première occurrence dans le DF\n",
        "            best = None\n",
        "            for i in range(sdf.shape[0]):\n",
        "                for j in range(sdf.shape[1]):\n",
        "                    cell = sdf.iat[i, j]\n",
        "                    c_norm = str(cell)\n",
        "                    hit = False\n",
        "                    for pat in patterns:\n",
        "                        # recherche tolérante (ignore spaces fines)\n",
        "                        pat_norm = str(pat).replace(\"\\u00A0\", \" \").strip()\n",
        "                        if pat_norm and pat_norm in c_norm:\n",
        "                            hit = True\n",
        "                            break\n",
        "                    if hit:\n",
        "                        row_label = \"\"\n",
        "                        try:\n",
        "                            if j != 0 and sdf.shape[1] > 0:\n",
        "                                row_label = sdf.iat[i, 0]\n",
        "                        except Exception:\n",
        "                            row_label = \"\"\n",
        "                        col_header = str(df.columns[j]) if j < len(df.columns) else f\"Col{j+1}\"\n",
        "                        # phrase compacte\n",
        "                        phrase = f\"{row_label} — {col_header}: {cell}\".strip()\n",
        "                        best = phrase\n",
        "                        break\n",
        "                if best:\n",
        "                    break\n",
        "\n",
        "            return best or \"\"\n",
        "        except Exception:\n",
        "            return \"\"\n",
        "\n",
        "    def _donut_answer(self, img: Image.Image, question: str) -> str:\n",
        "        \"\"\"\n",
        "        Appelle Donut et renvoie le texte de réponse.\n",
        "        \"\"\"\n",
        "        # Prépare le prompt Donut DocVQA\n",
        "        prompt = f\"<s_docvqa><s_question>{question}</s_question><s_answer>\"\n",
        "        pixel_values = self.donut_proc(img, return_tensors=\"pt\").pixel_values.to(self.donut_device)\n",
        "        decoder_input_ids = self.donut_proc.tokenizer(\n",
        "            prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
        "        ).input_ids.to(self.donut_device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = self.donut_model.generate(\n",
        "                pixel_values=pixel_values,\n",
        "                decoder_input_ids=decoder_input_ids,\n",
        "                max_length=decoder_input_ids.shape[-1] + self.max_donut_new_tokens,\n",
        "                early_stopping=True,\n",
        "                pad_token_id=self.donut_proc.tokenizer.pad_token_id,\n",
        "                eos_token_id=self.donut_proc.tokenizer.eos_token_id,\n",
        "                use_cache=True,\n",
        "                num_beams=1,\n",
        "                bad_words_ids=[[self.donut_proc.tokenizer.unk_token_id]],\n",
        "            )\n",
        "\n",
        "        seq = self.donut_proc.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        # Extraire ce qui suit <s_answer> si présent\n",
        "        if \"</s_answer>\" in seq:\n",
        "            ans = seq.split(\"<s_answer>\")[-1].split(\"</s_answer>\")[0].strip()\n",
        "        else:\n",
        "            # Donut renvoie parfois directement le texte après le prompt\n",
        "            ans = seq.replace(prompt, \"\").strip()\n",
        "        return ans\n",
        "\n",
        "\n",
        "    def _donut_vqa_extract(self, kpi_name: str, kpi_config: dict, allowed_docs: set | None = None) -> list[dict]:\n",
        "        \"\"\"\n",
        "        Donut DocVQA multi-candidats : renvoie une LISTE de candidats (<= table_llm_limit),\n",
        "        un par table candidate, si la valeur extraite est plausible.\n",
        "        \"\"\"\n",
        "        out = []\n",
        "        if not self._ensure_donut_ready():\n",
        "            return out\n",
        "\n",
        "        cand_tables = self._select_candidate_tables(\n",
        "            kpi_name, kpi_config, limit=self.table_llm_limit, allowed_docs=allowed_docs\n",
        "        )\n",
        "        if not cand_tables:\n",
        "            return out\n",
        "\n",
        "        question = kpi_config.get(\"question\", kpi_name)\n",
        "\n",
        "        for T in cand_tables:\n",
        "            img_path = T.get(\"image_crop_path\")\n",
        "            if not img_path:\n",
        "                continue\n",
        "\n",
        "            # image\n",
        "            try:\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "                mx = max(img.size)\n",
        "                if mx > 2200:\n",
        "                    s = 2200.0 / mx\n",
        "                    img = img.resize((int(img.width * s), int(img.height * s)), Image.BICUBIC)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            # prompt + conditioning\n",
        "            task_prompt = f\"<s_docvqa><s_question>{question}</s_question><s_answer>\"\n",
        "            try:\n",
        "                proc_in = self.donut_proc(images=img, text=task_prompt, return_tensors=\"pt\")\n",
        "                pixel_values = proc_in.pixel_values.to(self.donut_model.device)\n",
        "                input_ids    = proc_in.input_ids.to(self.donut_model.device)\n",
        "            except Exception as e:\n",
        "                print(f\"Donut preprocessing failed: {e}\")\n",
        "                continue\n",
        "\n",
        "            # génération bornée GPU-safe\n",
        "            def _generate(pixel_values, input_ids):\n",
        "                input_len = int(input_ids.shape[-1])\n",
        "                max_pos = int(getattr(self.donut_model.config.decoder, \"max_position_embeddings\", 512))\n",
        "                if input_len >= max_pos - 4:\n",
        "                    keep = max_pos - 8\n",
        "                    input_ids = input_ids[:, -keep:]\n",
        "                    input_len = int(input_ids.shape[-1])\n",
        "                allowed_new = max(1, min(int(getattr(self, \"max_donut_new_tokens\", 48)), max_pos - input_len - 2))\n",
        "                with torch.inference_mode():\n",
        "                    out = self.donut_model.generate(\n",
        "                        pixel_values=pixel_values,\n",
        "                        input_ids=input_ids,\n",
        "                        max_new_tokens=allowed_new,\n",
        "                        num_beams=1,\n",
        "                        do_sample=False,\n",
        "                        use_cache=True,\n",
        "                        eos_token_id=self.donut_proc.tokenizer.eos_token_id,\n",
        "                        pad_token_id=self.donut_proc.tokenizer.pad_token_id,\n",
        "                    )\n",
        "                seqs = out.sequences if hasattr(out, \"sequences\") else out\n",
        "                raw  = self.donut_proc.batch_decode(seqs, skip_special_tokens=True)[0].strip()\n",
        "                return raw\n",
        "\n",
        "            try:\n",
        "                raw = _generate(pixel_values, input_ids)\n",
        "            except Exception as e:\n",
        "                msg = str(e).lower()\n",
        "                if \"device-side assert\" in msg or \"cuda error\" in msg:\n",
        "                    print(\"Donut CUDA assert — retry on CPU with safe generation.\")\n",
        "                    try:\n",
        "                        self.donut_model = self.donut_model.to(\"cpu\")\n",
        "                        pixel_values = pixel_values.to(\"cpu\")\n",
        "                        input_ids    = input_ids.to(\"cpu\")\n",
        "                        raw = _generate(pixel_values, input_ids)\n",
        "                    except Exception as e2:\n",
        "                        print(f\"Donut retry on CPU failed: {e2}\")\n",
        "                        continue\n",
        "                else:\n",
        "                    print(f\"Donut failed on table (page {T.get('page')}): {e}\")\n",
        "                    continue\n",
        "\n",
        "            # réponse\n",
        "            ans = raw\n",
        "            if \"<s_answer>\" in raw:\n",
        "                ans = raw.split(\"<s_answer>\", 1)[-1].split(\"</s_answer>\")[0].strip()\n",
        "            else:\n",
        "                q_norm = question.strip()\n",
        "                pos = ans.find(q_norm)\n",
        "                if pos != -1:\n",
        "                    ans = ans[pos + len(q_norm):].strip()\n",
        "\n",
        "\n",
        "            m_all = re.findall(r\"([0-9][0-9\\.,]+\\b)\", ans) # Cherche des nombres purs\n",
        "            if not m_all: continue # Si pas de nombre, on ignore\n",
        "            val_str = m_all[-1]\n",
        "            val = self._coerce_float(val_str)\n",
        "            if val is None or val < 0: continue\n",
        "\n",
        "\n",
        "            # 2. Chercher l'année et l'unité dans un \"voisinage\" de la valeur trouvée\n",
        "            pos = ans.rfind(val_str)\n",
        "            window = 50 # On regarde 50 caractères avant et après\n",
        "            neighborhood = ans[max(0, pos - window): pos + len(val_str) + window]\n",
        "\n",
        "            # Recherche de l'année D'ABORD dans ce voisinage proche\n",
        "            year_matches = re.findall(r\"\\b(20\\d{2})\\b\", neighborhood)\n",
        "            year = max(map(int, year_matches)) if year_matches else None\n",
        "\n",
        "            # Si pas d'année proche, on cherche dans tout le contexte (texte du tableau + réponse)\n",
        "            if year is None:\n",
        "                search_text = (ans + \" \" + T.get(\"text\", \"\")).lower()\n",
        "                year_matches = re.findall(r\"\\b(20\\d{2})\\b\", search_text)\n",
        "                year = max(map(int, year_matches)) if year_matches else None\n",
        "\n",
        "            # Recherche de l'unité (logique inchangée, elle fonctionne bien)\n",
        "            unit_search_text = (ans + \" \" + T.get(\"text\", \"\")).lower()\n",
        "            unit = None\n",
        "            if \"ktco2e\" in unit_search_text or \"kt co2e\" in unit_search_text: unit = \"ktCO2e\"\n",
        "            elif \"tco2e\" in unit_search_text or \"tons co2eq\" in unit_search_text: unit = \"tCO2e\"\n",
        "            elif \"twh\" in unit_search_text: unit = \"TWh\"\n",
        "            elif \"gwh\" in unit_search_text: unit = \"GWh\"\n",
        "            elif \"%\" in unit_search_text: unit = \"%\"\n",
        "\n",
        "            if not self._validate_value_generic(unit, val):\n",
        "                continue\n",
        "\n",
        "            df = T.get(\"df\")\n",
        "            ctx = self._find_df_context_phrase(df, raw_answer=ans, value=val, unit_hint=unit)\n",
        "\n",
        "            if isinstance(val, (int, float)) and float(val).is_integer():\n",
        "                val_canon = str(int(val))\n",
        "            else:\n",
        "                val_canon = str(float(val)).rstrip(\"0\").rstrip(\".\")\n",
        "\n",
        "            answer_text_parts = []\n",
        "            if ctx:\n",
        "                answer_text_parts.append(ctx.strip())\n",
        "\n",
        "            at = \" — \".join(answer_text_parts) if answer_text_parts else \"\"\n",
        "            if val_canon not in at:\n",
        "                answer_text_parts.append(val_canon)\n",
        "\n",
        "            if unit:\n",
        "                unit_norm = unit.strip()\n",
        "                if unit_norm and unit_norm not in \" — \".join(answer_text_parts):\n",
        "                    answer_text_parts.append(unit_norm)\n",
        "\n",
        "            if year is not None:\n",
        "                y_str = str(int(year))\n",
        "                if y_str not in \" — \".join(answer_text_parts):\n",
        "                    answer_text_parts.append(y_str)\n",
        "\n",
        "            answer_text = \" — \".join(answer_text_parts).strip()\n",
        "\n",
        "            out.append({\n",
        "                \"source\": \"Donut-DocVQA\",\n",
        "                \"value\": float(val),\n",
        "                \"unit\": unit,\n",
        "                \"year\": year,\n",
        "                \"reason\": f\"Donut on table fp={T.get('fingerprint','')}\",\n",
        "                \"evidence\": f\"table on page {T.get('page')}\",\n",
        "                \"answer_text\": answer_text,\n",
        "                \"doc_type\": T.get(\"doc_type\",\"\"),\n",
        "                \"page\": T.get(\"page\"),\n",
        "                \"table_fp\": T.get(\"fingerprint\"),\n",
        "                \"image_crop_path\": T.get(\"image_crop_path\"),\n",
        "                \"bbox\": T.get(\"bbox\"),\n",
        "                \"bbox_page_pts\": T.get(\"bbox_page_pts\"),\n",
        "                \"judge_reason\": None,\n",
        "                \"judge_confidence\": None,\n",
        "            })\n",
        "        return out\n",
        "\n",
        "    def _ce_score(self, query: str, text: str) -> float:\n",
        "        try:\n",
        "            s = float(self.reranker.predict([(query, text)])[0])\n",
        "            return s\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "\n",
        "    def _coerce_float(self, x):\n",
        "        if x is None:\n",
        "            return None\n",
        "        if isinstance(x, (int, float)):\n",
        "            return float(x)\n",
        "        raw = str(x)\n",
        "        raw = raw.replace(\"\\u00A0\",\" \").replace(\"\\u2009\",\" \").replace(\"\\u202F\",\" \")\n",
        "        s = raw.strip()\n",
        "\n",
        "        # Accepter le groupage FR \"1 234 567\" -> \"1234567\"\n",
        "        if re.fullmatch(r\"\\d{1,3}(?:\\s\\d{3})+(?:[.,]\\d+)?\", s):\n",
        "            s = s.replace(\" \", \"\")\n",
        "        # Si espaces entre nombres mais que ce n'est PAS un groupage de milliers, on rejette (ex: \"81 0 25\")\n",
        "        elif re.search(r\"\\d+\\s+\\d+\", s):\n",
        "            return None\n",
        "        t = s\n",
        "        t = (t.replace(\"\\u00A0\",\"\").replace(\"\\u2009\",\"\").replace(\"\\u202F\",\"\").replace(\" \",\"\").replace(\"_\",\"\"))\n",
        "        t = t.replace(\"%\",\"\")\n",
        "        if t.count(\",\") > 0 and t.count(\".\") == 0:\n",
        "            t = t.replace(\",\", \".\")\n",
        "        else:\n",
        "            t = t.replace(\",\", \"\")\n",
        "        try:\n",
        "            return float(t)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def _validate_value_generic(self, unit: str | None, value: float | None) -> bool:\n",
        "        if value is None or not isinstance(value, (int, float)):\n",
        "            return False\n",
        "        v = float(value)\n",
        "        if not np.isfinite(v):\n",
        "            return False\n",
        "        if v < 0:\n",
        "            return False\n",
        "\n",
        "        unit_l = (unit or \"\").lower()\n",
        "        # Si l'unité contient %, alors la valeur doit être dans [0,100]\n",
        "        if \"%\" in unit_l and not (0 <= v <= 100):\n",
        "            return False\n",
        "\n",
        "        # ✅ On NE rejette plus les valeurs sans unité (elles seront triées au Judge)\n",
        "        return True\n",
        "\n",
        "\n",
        "\n",
        "    def _as_json_str(self, obj):\n",
        "        try:\n",
        "            return json.dumps(obj, ensure_ascii=False)\n",
        "        except Exception:\n",
        "            return str(obj)\n",
        "\n",
        "    def _flatten_candidate_for_csv(self, pillar: str, kpi_name: str, question: str, cand: dict) -> dict:\n",
        "        \"\"\"\n",
        "        Aplati un candidat (toutes sources) vers un dictionnaire CSV stable (schéma v3).\n",
        "        Cette version n'a plus besoin du score CE en entrée.\n",
        "        \"\"\"\n",
        "        # Calcul du score CE directement ici pour le logging\n",
        "        ev = \" \".join([str(cand.get(k) or \"\") for k in [\"answer_text\", \"reason\", \"evidence\"]]).strip()\n",
        "        try:\n",
        "            ce_ev = float(self._ce_score(question, ev))\n",
        "        except Exception:\n",
        "            ce_ev = 0.0\n",
        "\n",
        "        # Format de base unifié (schéma \"v3\" implicite)\n",
        "        base = {\n",
        "            \"schema_version\": \"v3\",\n",
        "            \"pillar\": pillar,\n",
        "            \"kpi_name\": kpi_name,\n",
        "            \"kpi_key\": f\"{pillar}_{kpi_name}\",\n",
        "            \"question\": question,\n",
        "            \"kpi_source\": cand.get(\"source\", \"\"),\n",
        "            \"value\": cand.get(\"value\"),\n",
        "            \"unit\": cand.get(\"unit\"),\n",
        "            \"year\": cand.get(\"year\"), # ✅ Ajout du champ année\n",
        "            \"answer_text\": cand.get(\"answer_text\") or str(cand.get(\"value\", \"\")),\n",
        "            \"ce_evidence\": ce_ev, # On le garde pour l'analyse\n",
        "            \"evidence_preview\": (cand.get(\"evidence\", \"\") or cand.get(\"reason\", \"\"))[:300],\n",
        "            # Champs communs\n",
        "            \"doc_type\": cand.get(\"doc_type\", \"\"),\n",
        "            \"page\": cand.get(\"page\"),\n",
        "            \"bbox_json\": self._as_json_str(cand.get(\"bbox\")),\n",
        "            \"table_fp\": cand.get(\"table_fp\", \"\"),\n",
        "            \"image_crop_path\": cand.get(\"image_crop_path\", \"\"),\n",
        "            # ✅ Ajout des champs du Judge (seront vides pour les candidats bruts)\n",
        "            \"judge_reason\": cand.get(\"judge_reason\"),\n",
        "            \"judge_confidence\": cand.get(\"judge_confidence\"),\n",
        "        }\n",
        "        return base\n",
        "\n",
        "    def _clean_table_df(self, df: pd.DataFrame) -> pd.DataFrame | None:\n",
        "        \"\"\"\n",
        "        Nettoie/normalise un DataFrame issu du parseur (PyMuPDF light tables / Camelot).\n",
        "        Version sans applymap (évite le FutureWarning).\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            return None\n",
        "        try:\n",
        "            # Aplatit les entêtes si MultiIndex\n",
        "            if isinstance(df.columns, pd.MultiIndex):\n",
        "                df.columns = [\n",
        "                    \" \".join([str(x).strip() for x in tup if str(x).strip()])\n",
        "                    for tup in df.columns.values\n",
        "                ]\n",
        "            else:\n",
        "                df.columns = [str(c).strip() for c in df.columns]\n",
        "\n",
        "            # Normalisations de base\n",
        "            df = df.replace(r\"\\s+\", \" \", regex=True)\n",
        "            df = df.replace({\"—\": \"\", \"–\": \"\", \"N/A\": \"\", \"NA\": \"\", \"n/a\": \"\"})\n",
        "\n",
        "            # ⚠️ Remplace applymap par map (pandas ≥2.1)\n",
        "            df = df.map(lambda x: str(x).strip())\n",
        "\n",
        "            # Drop vide\n",
        "            df = df.replace(\"\", np.nan)\n",
        "            df = df.dropna(how=\"all\", axis=0)\n",
        "            df = df.dropna(how=\"all\", axis=1)\n",
        "            if df.empty:\n",
        "                return None\n",
        "\n",
        "            # Élimine éventuelles lignes dupliquant exactement l'entête\n",
        "            header_tuple = tuple(df.columns)\n",
        "            to_drop = []\n",
        "            for i, row in df.iterrows():\n",
        "                if tuple(row.values) == header_tuple:\n",
        "                    to_drop.append(i)\n",
        "            if to_drop:\n",
        "                df = df.drop(index=to_drop)\n",
        "\n",
        "            # Garde-fous\n",
        "            if df.shape[1] > 40:\n",
        "                df = df.iloc[:, :40]\n",
        "            if df.shape[0] > 1000:\n",
        "                df = df.iloc[:1000, :]\n",
        "\n",
        "            return df if not df.empty else None\n",
        "        except Exception:\n",
        "            return None\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Chargement & preprocessing (PyMuPDF + PerfectTables)\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _load_and_process_documents(self, document_paths: dict):\n",
        "        \"\"\"\n",
        "        Extraction du TEXTE par PyMuPDF (pour RAG) + TABLES via PerfectTables UNIQUEMENT.\n",
        "        \"\"\"\n",
        "        print(\"\\n--- Loading & Processing Documents (PerfectTables + PDF text) ---\")\n",
        "        self.page_texts = []\n",
        "        self.chunks = []\n",
        "        self.tables = []\n",
        "        self.chunk_doc_types = []\n",
        "        self.analysis_state = {\n",
        "            \"sources_provided\": [],\n",
        "            \"total_pages\": 0,\n",
        "            \"detected_sector\": \"unknown\",\n",
        "        }\n",
        "\n",
        "        total_tables_found = 0\n",
        "\n",
        "        for doc_type, path in document_paths.items():\n",
        "            if not path:\n",
        "                continue\n",
        "            if not os.path.exists(path):\n",
        "                print(f\"  >> WARNING: missing file for '{doc_type}': {path}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  -> Processing {doc_type} ({os.path.basename(path)})\")\n",
        "            self.analysis_state[\"sources_provided\"].append(doc_type)\n",
        "\n",
        "            if path.lower().endswith(\".pdf\"):\n",
        "                # 1) TEXTE (pour RAG / sector detection)\n",
        "                try:\n",
        "                    doc = fitz.open(path)\n",
        "                    pages = len(doc)\n",
        "                    for pidx in range(pages):\n",
        "                        try:\n",
        "                            txt = doc[pidx].get_text(\"text\") or \"\"\n",
        "                        except Exception:\n",
        "                            txt = \"\"\n",
        "                        if txt and len(txt.split()) > 5:\n",
        "                            chunk = clean_text_spacy(txt)\n",
        "                            if chunk:\n",
        "                                self.chunks.append(chunk)\n",
        "                                self.chunk_doc_types.append(doc_type)\n",
        "                                self.page_texts.append((pidx + 1, doc_type, chunk))\n",
        "                    doc.close()\n",
        "                    self.analysis_state[\"total_pages\"] += pages\n",
        "                except Exception as e:\n",
        "                    print(f\"  ERROR: cannot open PDF for text: {e}\")\n",
        "\n",
        "                # 2) TABLES (PerfectTables only)\n",
        "                try:\n",
        "                    pt_tables = extract_tables_from_pdf(path, self.image_dir, doc_type)\n",
        "                except Exception as e:\n",
        "                    print(f\"  ERROR: PerfectTables failed on {os.path.basename(path)}: {e}\")\n",
        "                    pt_tables = []\n",
        "\n",
        "                for t in pt_tables:\n",
        "                    df = self._clean_table_df(t.get(\"df\"))\n",
        "                    if df is None or df.empty:\n",
        "                        continue\n",
        "\n",
        "                    # largeur/hauteur du crop\n",
        "                    try:\n",
        "                        bx = t.get(\"bbox\") or []\n",
        "                        W = float(bx[2] - bx[0]); H = float(bx[3] - bx[1])\n",
        "                        if not (W > 0 and H > 0):\n",
        "                            raise ValueError(\"bad bbox\")\n",
        "                    except Exception:\n",
        "                        try:\n",
        "                            with Image.open(t.get(\"image_crop_path\")) as im:\n",
        "                                W, H = im.size\n",
        "                        except Exception:\n",
        "                            W, H = 1000.0, 1000.0  # garde-fou\n",
        "\n",
        "                    bbox_rel = [0.0, 0.0, float(W), float(H)]\n",
        "\n",
        "                    # aperçu texte\n",
        "                    headers = \" | \".join(map(str, list(df.columns)))\n",
        "                    first_col = \" | \".join(map(str, list(df.iloc[:, 0].astype(str).values[:10]))) if df.shape[1] > 0 else \"\"\n",
        "                    table_text_representation = t.get(\"text\") or f\"Table: {headers} || first_col: {first_col}\"\n",
        "\n",
        "                    record = {\n",
        "                        \"page\": int(t.get(\"page\") or 0),\n",
        "                        \"df\": df,\n",
        "                        \"text\": table_text_representation,\n",
        "                        \"doc_type\": doc_type,\n",
        "                        \"bbox\": bbox_rel,                              # (0,0,W,H) ≡ coords du crop\n",
        "                        \"cells\": t.get(\"cells\", []),                   # pas requis par Donut, gardé pour debug\n",
        "                        \"image_crop_path\": t.get(\"image_crop_path\"),\n",
        "                        \"fingerprint\": t.get(\"fingerprint\") or self._fingerprint_table(df),\n",
        "                        \"bbox_page_pts\": t.get(\"bbox_page_pts\"),\n",
        "                    }\n",
        "                    self.tables.append(record)\n",
        "\n",
        "                    # linearisation pour l’index texte\n",
        "                    lin = linearize_table(df, source_page=int(t.get(\"page\") or 0))\n",
        "\n",
        "                    header_text = \" \".join(map(str, list(df.columns)))\n",
        "                    semantic_bait = f\"What are the values for {header_text}? \"\n",
        "                    prefix = f\"[DATA TABLE from page {int(t.get('page') or 0)}]\"\n",
        "                    prefixed_lin = [prefix + l for l in lin]\n",
        "                    self.chunks.extend(prefixed_lin)\n",
        "                    self.chunk_doc_types.extend([doc_type] * len(prefixed_lin))\n",
        "\n",
        "                    total_tables_found += 1\n",
        "\n",
        "            elif path.lower().endswith(\".txt\"):\n",
        "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    txt = clean_text_spacy(f.read())\n",
        "                    if txt:\n",
        "                        self.chunks.append(txt)\n",
        "                        self.chunk_doc_types.append(doc_type)\n",
        "\n",
        "        print(f\"--- Done. {len(self.chunks)} knowledge chunks and {len(self.tables)} tables collected (PerfectTables={total_tables_found}). ---\")\n",
        "        self._table_sanity_report()\n",
        "\n",
        "    def _table_sanity_report(self, sample: int = 5):\n",
        "        n = len(self.tables)\n",
        "        if n == 0:\n",
        "            print(\">>> TABLE SANITY: No tables parsed.\")\n",
        "            return\n",
        "        numeric_tables = 0\n",
        "        for t in self.tables[:sample]:\n",
        "            df = t[\"df\"]\n",
        "            txt = \" | \".join(map(str, df.columns))\n",
        "            sub = df.head(30).astype(str).values.ravel().tolist()\n",
        "            nums = sum(1 for s in sub if re.search(r\"\\d\", s))\n",
        "            if nums > 0: numeric_tables += 1\n",
        "            print(f\"    • Page {t['page']}: shape={df.shape}, header≈ [{txt[:80]}...] nums_in_head30={nums}\")\n",
        "        print(f\">>> TABLE SANITY: {n} tables total, {numeric_tables}/{min(n, sample)} with numeric content in preview.\")\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Index hybride (FAISS + BM25)\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _build_index(self):\n",
        "        \"\"\"\n",
        "        Construit l'index hybride en limitant la mémoire:\n",
        "        - embeddings encodés en batch (CPU) -> float32\n",
        "        - normalisation L2 + FAISS IP\n",
        "        \"\"\"\n",
        "        if not self.chunks and not self.tables:\n",
        "            print(\"ERROR: Cannot build index (no content).\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n--- Building Hybrid Index (Semantic FAISS + Lexical BM25) ---\")\n",
        "        if self.chunks:\n",
        "            print(f\"  -> Indexing {len(self.chunks)} text chunks (batch={self.embedding_batch_size})...\")\n",
        "            embs = self.embedding_model.encode(\n",
        "                self.chunks,\n",
        "                batch_size=self.embedding_batch_size,\n",
        "                show_progress_bar=True,\n",
        "            )\n",
        "            embs = np.ascontiguousarray(embs, dtype=np.float32)\n",
        "            faiss.normalize_L2(embs)\n",
        "            self.all_embeddings = embs\n",
        "            self.faiss_index = faiss.IndexFlatIP(self.embedding_dim)\n",
        "            self.faiss_index.add(self.all_embeddings)\n",
        "\n",
        "            tokenized_corpus = [doc.lower().split(\" \") for doc in self.chunks]\n",
        "            self.bm25_index = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "        print(f\"--- Hybrid Index ready. ---\")\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Détection secteur (LLM), limité aux pages 1–5\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    def _detect_industry_sector(self):\n",
        "        if not self.page_texts:\n",
        "            print(\"No content loaded; sector detection skipped.\")\n",
        "            self.analysis_state[\"detected_sector\"] = \"unknown\"\n",
        "            return\n",
        "\n",
        "        print(\"\\n--- Industry Sector Detection (pages 1–5) ---\")\n",
        "        first_pages = [t for t in self.page_texts if t[0] <= 5]\n",
        "        context = \" \".join(t[2] for t in first_pages[:10])\n",
        "        sector_choices = \", \".join(SECTOR_LIST)\n",
        "        question = f\"Based on the text, what is the primary industry sector? Choose from: {sector_choices}.\"\n",
        "\n",
        "        # Prompt de \"guidage\"\n",
        "        format_json = '{\"sector\":\"...\"}'\n",
        "        system_message = (\n",
        "            \"You are an expert financial analyst. First, think step-by-step in a <think> block to determine the sector. \"\n",
        "            \"Then, provide the answer as a single, compact JSON object and nothing else.\"\n",
        "        )\n",
        "        user_message = (\n",
        "            f\"SECTOR LIST: {sector_choices}\\n\\n\"\n",
        "            f\"CONTEXT:\\n{context}\\n\\n\"\n",
        "            f\"QUESTION: {question}\\n\\n\"\n",
        "            f\"FINAL ANSWER FORMAT:\\n{format_json}\"\n",
        "        )\n",
        "\n",
        "        # Logique de génération standardisée\n",
        "        raw_output = self._generate_text(system_message, user_message, max_new_tokens=500)\n",
        "        final_answer = self._strip_think(raw_output)\n",
        "        js = self._extract_first_json_object(final_answer)\n",
        "\n",
        "        detected = \"unknown\"\n",
        "        if js:\n",
        "            try:\n",
        "                obj = self._json_loads_lenient(js)\n",
        "                if obj and isinstance(obj, dict) and \"sector\" in obj:\n",
        "                    # On s'assure que le secteur détecté est bien dans la liste autorisée\n",
        "                    cand = str(obj[\"sector\"]).strip()\n",
        "                    for s in SECTOR_LIST:\n",
        "                        if s.lower() == cand.lower():\n",
        "                            detected = s\n",
        "                            break\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Fallback (inchangé)\n",
        "        if detected == \"unknown\" and final_answer:\n",
        "            txt = final_answer.lower()\n",
        "            for sector in SECTOR_LIST:\n",
        "                if sector.lower() in txt:\n",
        "                    detected = sector\n",
        "                    break\n",
        "\n",
        "        self.analysis_state[\"detected_sector\"] = detected\n",
        "        print(f\"  -> Detected sector: '{detected}'\")\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Sélection de tables candidates (PerfectTables embeddings)\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _select_candidate_tables(self, kpi_name: str, kpi_config: dict, limit: int = 3, allowed_docs: set | None = None):\n",
        "        if not self.tables:\n",
        "            return []\n",
        "\n",
        "        kpi_question = kpi_config.get(\"question\", kpi_name)\n",
        "\n",
        "        # Embedding de la question\n",
        "        q_vec = self.embedding_model.encode(kpi_question, convert_to_numpy=True)\n",
        "        q_vec = np.asarray(q_vec, dtype=np.float32)\n",
        "        faiss.normalize_L2(q_vec.reshape(1, -1))\n",
        "\n",
        "        # ⚠️ normalise le filtre et le doc_type comme dans ton debug\n",
        "        allow_norm = {d.strip().lower() for d in (allowed_docs or set())}\n",
        "\n",
        "        scored = []\n",
        "        for t in self.tables:\n",
        "            t_doc = str(t.get(\"doc_type\",\"\")).strip().lower()\n",
        "            if allow_norm and t_doc not in allow_norm:\n",
        "                continue\n",
        "\n",
        "            df = t.get(\"df\")\n",
        "            if df is None or getattr(df, \"empty\", False):\n",
        "                continue\n",
        "\n",
        "            # même fallback que dans ton calcul manuel\n",
        "            text_repr = t.get(\"text\") or (\" | \".join(map(str, df.columns)))\n",
        "\n",
        "            # embedding du tableau (cache sur l’objet table)\n",
        "            vec = t.get(\"embedding\")\n",
        "            if vec is None:\n",
        "                vec = self.embedding_model.encode(text_repr, convert_to_numpy=True)\n",
        "                vec = np.asarray(vec, dtype=np.float32)\n",
        "                faiss.normalize_L2(vec.reshape(1, -1))\n",
        "                t[\"embedding\"] = vec\n",
        "\n",
        "            sem = float(np.dot(q_vec.ravel(), vec.ravel()))\n",
        "            header = \" | \".join(map(str, df.columns))\n",
        "            first_col = \" | \".join(map(str, df.iloc[:,0].astype(str).values[:20])) if df.shape[1] > 0 else \"\"\n",
        "            ce = self._ce_score(kpi_question, (t.get(\"text\") or (header + \" | \" + first_col)))\n",
        "            dens = self._numeric_density(df)\n",
        "            latest_bonus = 0.6 if (self._find_latest_year_col(df) is not None) else 0.0\n",
        "\n",
        "            score = sem * 10.0 + ce * 2.0 + dens * 1.0 + latest_bonus\n",
        "            scored.append((score, t))\n",
        "\n",
        "        ranked = sorted(scored, key=lambda x: x[0], reverse=True)\n",
        "        return [t for _, t in ranked[:max(1, limit)]]\n",
        "\n",
        "\n",
        "    def _numeric_density(self, df: pd.DataFrame) -> float:\n",
        "        vals = df.astype(str).values.ravel().tolist()\n",
        "        if not vals: return 0.0\n",
        "        nums = sum(1 for v in vals if re.search(r\"\\d\", v or \"\"))\n",
        "        return nums / float(len(vals))\n",
        "\n",
        "    def _find_latest_year_col(self, df: pd.DataFrame):\n",
        "        candidates = []\n",
        "        for j, col in enumerate(df.columns):\n",
        "            years = re.findall(r\"(20\\d{2})\", str(col))\n",
        "            if years: candidates.append((j, max(map(int, years))))\n",
        "        if not candidates: return None\n",
        "        return max(candidates, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "    def _log_kpi_candidates(self, pillar: str, kpi_name: str, question: str, candidates: list[dict]):\n",
        "        \"\"\"\n",
        "        Log des candidats (schéma v3). Gère l'écriture et la mise à jour de l'en-tête du CSV.\n",
        "        \"\"\"\n",
        "        if not candidates:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Prépare les lignes pour le CSV en utilisant la nouvelle fonction flatten\n",
        "            rows = [self._flatten_candidate_for_csv(pillar, kpi_name, question, c) for c in candidates]\n",
        "\n",
        "            # S'assure que le dossier existe\n",
        "            os.makedirs(os.path.dirname(self.candidates_log_csv), exist_ok=True)\n",
        "\n",
        "            # Définit l'ordre des colonnes une fois pour toutes pour la cohérence\n",
        "            # On utilise les clés de la première ligne comme référence\n",
        "            header = list(rows[0].keys())\n",
        "\n",
        "            # Vérifie si le fichier a besoin d'une en-tête\n",
        "            write_header = not os.path.exists(self.candidates_log_csv)\n",
        "\n",
        "            with open(self.candidates_log_csv, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=header, delimiter=CSV_DELIM, extrasaction='ignore')\n",
        "\n",
        "                if write_header:\n",
        "                    writer.writeheader()\n",
        "\n",
        "                writer.writerows(rows)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] CSV logging failed for {pillar}_{kpi_name}: {e}\")\n",
        "    # --------------------------------------------------------------------------\n",
        "    # RAG (Hybride + BGE) → JSON\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _rerank_doc_ids(self, question: str, doc_ids: list[int], top_k: int) -> list[int]:\n",
        "        if not doc_ids:\n",
        "            return []\n",
        "        texts = [self.chunks[i] for i in doc_ids]\n",
        "        try:\n",
        "            scores = self.reranker.predict([(question, t) for t in texts])\n",
        "            order = list(np.argsort(scores)[::-1])\n",
        "            return [doc_ids[i] for i in order[:top_k]]\n",
        "        except Exception:\n",
        "            return doc_ids[:top_k]\n",
        "\n",
        "    def _query_rag_hybrid(self, kpi_name: str, kpi_config: dict, k: int = 3, allowed_docs: set | None = None) -> list[dict]:\n",
        "        \"\"\"\n",
        "        RAG Hybride multi-candidats (STRICT). Génère ≤ k candidats (1 par contexte reranké),\n",
        "        avec règles strictes + sanity-check \"valeur présente dans le contexte\".\n",
        "        \"\"\"\n",
        "        out = []\n",
        "        try:\n",
        "            question_long = kpi_config.get(\"question\", kpi_name)\n",
        "            search_query  = kpi_config.get(\"search_query\", question_long)\n",
        "\n",
        "            # ---- 1) Retrieve BM25 + FAISS\n",
        "            indices = []\n",
        "            if self.bm25_index is not None and self.chunks:\n",
        "                toks = search_query.lower().split(\" \")\n",
        "                bm25_scores = self.bm25_index.get_scores(toks)\n",
        "                bm25_top = np.argsort(bm25_scores)[::-1][:max(self.rag_top_candidates//2, k)]\n",
        "                indices.extend(bm25_top.tolist())\n",
        "\n",
        "            if self.faiss_index is not None and self.chunks:\n",
        "                q_emb = self.embedding_model.encode([search_query], convert_to_numpy=True)\n",
        "                q_emb = np.ascontiguousarray(q_emb, dtype=np.float32)\n",
        "                faiss.normalize_L2(q_emb)\n",
        "                _, faiss_top = self.faiss_index.search(q_emb, max(self.rag_top_candidates//2, k))\n",
        "                indices.extend(faiss_top[0].tolist())\n",
        "\n",
        "            # dédoublonne + filtre types\n",
        "            indices = list(dict.fromkeys(indices))\n",
        "            if allowed_docs:\n",
        "                indices = [i for i in indices if self.chunk_doc_types[i] in allowed_docs]\n",
        "            if not indices:\n",
        "                return []\n",
        "\n",
        "            # ---- 2) Rerank (BGE) → top ≤ k contextes\n",
        "            top_ids = self._rerank_doc_ids(search_query, indices, top_k=max(k, self.rag_top_k_context))\n",
        "            top_ids = top_ids[:max(1, k)]\n",
        "\n",
        "            # ---- 3) Prompt strict (with-think) + génération\n",
        "            JSON_FORMAT = (\n",
        "                '{\"reasoning\":\"<short evidence>\", '\n",
        "                '\"current_value\": 1234.5, '\n",
        "                '\"unit\": \"tCO2e|ktCO2e|null\", '\n",
        "                '\"year\": 2024, '\n",
        "                '\"is_present\": true}'\n",
        "            )\n",
        "            STRICT_RULES = (\n",
        "                \"Rules:\\n\"\n",
        "                \"1) If you cannot find an explicit number for the QUESTION in CONTEXT, return exactly: \"\n",
        "                '{\"reasoning\":\"not found\", \"current_value\": null, \"unit\": null, \"year\": null, \"is_present\": false}\\n'\n",
        "                \"2) Copy digits verbatim from CONTEXT. Do not reorder, do not guess. \"\n",
        "                \"If you write 15,571 in reasoning, current_value must be 15571 (commas/spaces removed).\\n\"\n",
        "                \"3) Year must be a 4-digit year seen in CONTEXT.\\n\"\n",
        "                \"4) unit ∈ {tCO2e, ktCO2e} or null.\\n\"\n",
        "                \"5) Output ONE JSON object only. First char must be '{'. No extra text.\"\n",
        "            )\n",
        "            system_message = (\n",
        "                \"You are a precise data extraction expert.\\n\"\n",
        "                \"First, think step-by-step inside a <think> block (≤60 tokens) to locate the number in the CONTEXT.\\n\"\n",
        "                \"Then output exactly ONE JSON object and nothing else.\\n\" + STRICT_RULES\n",
        "            )\n",
        "\n",
        "            num_pat  = re.compile(r\"\\b\\d{1,3}(?:[ ,.\\u00A0]\\d{3})*(?:[.,]\\d+)?\\b\")\n",
        "            year_pat = re.compile(r\"\\b20\\d{2}\\b\")\n",
        "\n",
        "            def _numbers_in_ctx(ctx: str) -> set[float]:\n",
        "                spans = num_pat.findall(ctx or \"\")\n",
        "                vals = set()\n",
        "                for s in spans:\n",
        "                    v = self._coerce_float(s)\n",
        "                    if v is not None:\n",
        "                        vals.add(float(v))\n",
        "                return vals\n",
        "\n",
        "            for idx in top_ids:\n",
        "                context = self.chunks[idx]\n",
        "                doc_type = self.chunk_doc_types[idx]\n",
        "\n",
        "                user_message = f\"CONTEXT:\\n{context}\\n\\nQUESTION: {search_query}\\n\\nFINAL ANSWER FORMAT:\\n{JSON_FORMAT}\"\n",
        "\n",
        "                raw_output = self._generate_text(system_message, user_message, max_new_tokens=512)\n",
        "                final_answer = self._strip_think(raw_output)\n",
        "                js_str = self._extract_first_json_object(final_answer)\n",
        "                if not js_str:\n",
        "                    continue\n",
        "\n",
        "                data = self._json_loads_lenient(js_str)\n",
        "                if not isinstance(data, dict):\n",
        "                    continue\n",
        "\n",
        "                # respect du fallback \"not found\"\n",
        "                isp = str(data.get(\"is_present\", \"\")).strip().lower()\n",
        "                if isp in {\"false\", \"0\", \"no\"}:\n",
        "                    continue\n",
        "\n",
        "                # parse strict du JSON (sans rescue)\n",
        "                val = self._coerce_float(data.get(\"current_value\"))\n",
        "                if val is None:\n",
        "                    continue\n",
        "\n",
        "                unit = data.get(\"unit\")\n",
        "                if isinstance(unit, str):\n",
        "                    u = unit.lower().replace(\" \", \"\")\n",
        "                    if \"ktco2\" in u:\n",
        "                        unit = \"ktCO2e\"\n",
        "                    elif \"tco2e\" in u or \"ton\" in u or \"tons\" in u:\n",
        "                        unit = \"tCO2e\"\n",
        "                    else:\n",
        "                        unit = None\n",
        "                else:\n",
        "                    unit = None\n",
        "\n",
        "                year = None\n",
        "                y = data.get(\"year\")\n",
        "                if isinstance(y, (int, float)):\n",
        "                    year = int(y)\n",
        "                elif isinstance(y, str):\n",
        "                    m = re.search(r\"\\b20\\D?(\\d{2})\\b\", y)\n",
        "                    if m:\n",
        "                        year = int(\"20\" + m.group(1))\n",
        "\n",
        "                # ---- 4) Sanity: valeur & année doivent être dans le CONTEXT\n",
        "                present_nums = _numbers_in_ctx(context)\n",
        "                val_ok = (val in present_nums)\n",
        "                # tolérer kt ↔ t\n",
        "                if not val_ok and unit == \"ktCO2e\" and (val * 1000.0) in present_nums:\n",
        "                    val_ok = True\n",
        "                if not val_ok and unit == \"tCO2e\" and (val / 1000.0) in present_nums:\n",
        "                    val_ok = True\n",
        "                if not val_ok:\n",
        "                    continue\n",
        "\n",
        "                if unit not in (None, \"tCO2e\", \"ktCO2e\"):\n",
        "                    continue\n",
        "                if year is not None and not year_pat.search(context or \"\"):\n",
        "                    # si l'année proposée n'apparaît pas dans le contexte, on l'ignore (mais on garde le candidat)\n",
        "                    year = None\n",
        "\n",
        "                if not self._validate_value_generic(unit, val):\n",
        "                    continue\n",
        "\n",
        "                # ---- 5) Candidat\n",
        "                out.append({\n",
        "                    \"source\": \"RAG+LLM\",\n",
        "                    \"value\": float(val),\n",
        "                    \"unit\": unit,\n",
        "                    \"year\": year,\n",
        "                    \"reason\": data.get(\"reasoning\", \"Generated by RAG.\"),\n",
        "                    \"evidence\": context[:800],\n",
        "                    \"answer_text\": data.get(\"reasoning\", str(val)),\n",
        "                    \"doc_type\": doc_type,\n",
        "                    \"page\": None,\n",
        "                    \"table_fp\": None,\n",
        "                    \"image_crop_path\": None,\n",
        "                    \"bbox\": None,\n",
        "                    \"bbox_page_pts\": None,\n",
        "                    \"judge_reason\": None,\n",
        "                    \"judge_confidence\": None,\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR in _query_rag_hybrid for '{kpi_name}': {e}\")\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Résumé global / confiance\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _build_summary_context(self, extracted_kpis: dict, max_chunks: int = 12, allowed_docs: set | None = None) -> str:\n",
        "        active_questions = []\n",
        "        for pillar, kpis in KPI_FRAMEWORK.items():\n",
        "            for k, cfg in kpis.items():\n",
        "                if extracted_kpis.get(pillar, {}).get(k, {}).get(\"values\", {}).get(\"is_present\"):\n",
        "                    active_questions.append(cfg.get(\"question\", k))\n",
        "        if not active_questions:\n",
        "            active_questions = [cfg.get(\"question\", k) for p, kpis in KPI_FRAMEWORK.items() for k, cfg in kpis.items()]\n",
        "            active_questions = active_questions[:12]\n",
        "\n",
        "        combined_query = \" \".join(active_questions)[:2000]\n",
        "        idxs = [i for i in range(len(self.chunks)) if (not allowed_docs or self.chunk_doc_types[i] in allowed_docs)]\n",
        "        if not idxs:\n",
        "            return \"\"\n",
        "\n",
        "        cand = []\n",
        "        try:\n",
        "            if self.bm25_index is not None and self.chunks:\n",
        "                tokenized = combined_query.lower().split(\" \")\n",
        "                bm_scores = self.bm25_index.get_scores(tokenized)\n",
        "                bm_top = np.argsort(bm_scores)[::-1][:min(30, len(bm_scores))]\n",
        "                cand.extend(bm_top.tolist())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            if self.faiss_index is not None and self.chunks:\n",
        "                q_emb = self.embedding_model.encode([combined_query], convert_to_numpy=True)\n",
        "                q_emb = np.ascontiguousarray(q_emb, dtype=np.float32); faiss.normalize_L2(q_emb)\n",
        "                _, fa_top = self.faiss_index.search(q_emb, min(30, len(idxs)))\n",
        "                cand.extend(fa_top[0].tolist())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # dédoublonne et garde seulement ceux autorisés\n",
        "        cand = [i for i in dict.fromkeys(cand) if i in idxs]\n",
        "        if not cand:\n",
        "            cand = idxs[:min(120, len(idxs))]\n",
        "\n",
        "        top_ids = self._rerank_doc_ids(combined_query, cand, top_k=max(4, min(max_chunks, len(cand))))\n",
        "        return \"\\n---\\n\".join(self.chunks[i] for i in top_ids)\n",
        "\n",
        "\n",
        "    def _calculate_confidence_score(self, extracted_kpis: dict) -> float:\n",
        "        source_weights = {'sustainability': 0.6, 'financial': 0.3, 'controversies': 0.1}\n",
        "        provided = set(self.analysis_state.get('sources_provided', []))\n",
        "        base_confidence = sum(source_weights.get(s, 0.0) for s in provided)\n",
        "        base_confidence = min(1.0, base_confidence)\n",
        "        total_kpis = sum(len(kpis) for kpis in KPI_FRAMEWORK.values()) or 1\n",
        "        found_kpis = sum(1 for pillar_data in extracted_kpis.values() for kpi_data in pillar_data.values()\n",
        "                        if kpi_data.get('values', {}).get('current') is not None)\n",
        "        data_density = found_kpis / total_kpis\n",
        "        return float(max(0.0, min(1.0, 0.5 * base_confidence + 0.5 * data_density)))\n",
        "\n",
        "\n",
        "    def _generate_global_opinion(self, main_context: str, contro_context: str = \"\") -> dict:\n",
        "        format_json = '{\"global_opinion\":\"...\", \"key_risks\":[\"...\", \"...\"], \"controversy_comment\": \"\"}'\n",
        "\n",
        "        # Prompt de \"guidage\"\n",
        "        system_message = (\n",
        "            \"You are an equity/ESG analyst. First, think step-by-step in a <think> block to structure your thoughts. \"\n",
        "            \"Base 'global_opinion' and 'key_risks' ONLY on MAIN_CONTEXT. \"\n",
        "            \"If CONTRO_CONTEXT is not empty, add a 'controversy_comment'. \"\n",
        "            \"Then, provide your final analysis as a single, compact JSON object and nothing else.\"\n",
        "        )\n",
        "        user_message = f\"MAIN_CONTEXT:\\n{main_context}\\n\\nCONTRO_CONTEXT:\\n{contro_context}\\n\\nFINAL ANSWER FORMAT:\\n{format_json}\"\n",
        "\n",
        "        # Logique de génération standardisée\n",
        "        raw_output = self._generate_text(system_message, user_message, max_new_tokens=550)\n",
        "        final_answer = self._strip_think(raw_output)\n",
        "\n",
        "        # Cherche le JSON dans la réponse nettoyée\n",
        "        js_str = self._extract_first_json_object(final_answer)\n",
        "        if js_str:\n",
        "            try:\n",
        "                obj = self._json_loads_lenient(js_str)\n",
        "                if obj and isinstance(obj, dict):\n",
        "                    return {\n",
        "                        \"global_opinion\": obj.get(\"global_opinion\", \"\"),\n",
        "                        \"key_risks\": obj.get(\"key_risks\", []),\n",
        "                        \"controversy_comment\": obj.get(\"controversy_comment\", \"\")\n",
        "                    }\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Fallback si pas de JSON valide\n",
        "        return {\"global_opinion\": \"\", \"key_risks\": [], \"controversy_comment\": \"\"}\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Cache (préprocess) : save/load\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _preprocess_and_save_to_cache(self, document_paths: dict):\n",
        "        self._load_and_process_documents(document_paths)\n",
        "        if not self.chunks and not self.tables:\n",
        "            print(\"ERROR: Preprocessing failed, no content extracted.\")\n",
        "            return\n",
        "        self._build_index()\n",
        "        print(\"\\n--- Saving preprocessed data to cache... ---\")\n",
        "        with open(self.cache_files[\"chunks\"], \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\"chunks\": self.chunks, \"doc_types\": self.chunk_doc_types, \"page_texts\": self.page_texts}, f)\n",
        "        pd.to_pickle(self.tables, self.cache_files[\"tables\"])\n",
        "        np.save(self.cache_files[\"embeddings\"], self.all_embeddings)\n",
        "        pd.to_pickle(self.bm25_index, self.cache_files[\"bm25\"])\n",
        "        print(\"--- Caching complete. ---\")\n",
        "\n",
        "    def _load_from_cache(self):\n",
        "        with open(self.cache_files[\"chunks\"], \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "            self.chunks = data[\"chunks\"]; self.chunk_doc_types = data[\"doc_types\"]; self.page_texts = data.get(\"page_texts\",[])\n",
        "        self.tables = pd.read_pickle(self.cache_files[\"tables\"])\n",
        "        self.all_embeddings = np.load(self.cache_files[\"embeddings\"])\n",
        "        self.bm25_index = pd.read_pickle(self.cache_files[\"bm25\"])\n",
        "        print(\"  -> Rebuilding FAISS index from cached embeddings...\")\n",
        "        self.faiss_index = faiss.IndexFlatIP(self.embedding_dim); self.faiss_index.add(self.all_embeddings)\n",
        "        print(f\"--- Loaded {len(self.chunks)} chunks and {len(self.tables)} tables from cache. ---\")\n",
        "\n",
        "    def _purge_cache_artifacts(self, cache_prefix: str, force: bool, phase: str = \"pre\"):\n",
        "        \"\"\"\n",
        "        Purge/refresh des artefacts de cache et des crops PNG pour un PDF donné (cache_prefix).\n",
        "        - phase=\"pre\":  si force=True, supprime les fichiers de cache et le dossier images/<cache_prefix>, puis recrée le dossier.\n",
        "        - phase=\"post\": supprime les PNG orphelins non référencés par self.tables (sécurité).\n",
        "        \"\"\"\n",
        "        import shutil\n",
        "\n",
        "        img_dir = os.path.join(self.cache_dir, \"images\", cache_prefix)\n",
        "\n",
        "        if phase == \"pre\":\n",
        "            if force:\n",
        "                try:\n",
        "                    for p in (self.cache_files or {}).values():\n",
        "                        if p and os.path.exists(p):\n",
        "                            os.remove(p)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                shutil.rmtree(img_dir, ignore_errors=True)\n",
        "\n",
        "            os.makedirs(img_dir, exist_ok=True)\n",
        "            self.image_dir = img_dir\n",
        "            return\n",
        "\n",
        "        if phase == \"post\":\n",
        "            try:\n",
        "                if not os.path.isdir(img_dir):\n",
        "                    return\n",
        "                used = set()\n",
        "                for t in (self.tables or []):\n",
        "                    p = t.get(\"image_crop_path\")\n",
        "                    if p:\n",
        "                        used.add(os.path.abspath(p))\n",
        "                for fname in os.listdir(img_dir):\n",
        "                    if not fname.lower().endswith(\".png\"):\n",
        "                        continue\n",
        "                    fp = os.path.abspath(os.path.join(img_dir, fname))\n",
        "                    if fp not in used:\n",
        "                        try:\n",
        "                            os.remove(fp)\n",
        "                        except Exception:\n",
        "                            pass\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Features → CSV (pour futur ranker)\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _candidate_features(self, question: str, candidates: list[dict]) -> list[dict]:\n",
        "        ce_evidences, evidences = [], []\n",
        "        ce_answers = []\n",
        "\n",
        "        for c in candidates:\n",
        "            ev = f\"{c.get('reason','')} {c.get('evidence','')}\".strip()\n",
        "            evidences.append(ev)\n",
        "            try:\n",
        "                ce_evidences.append(float(self._ce_score(question, ev)))\n",
        "            except Exception:\n",
        "                ce_evidences.append(0.0)\n",
        "\n",
        "            answer_text = (c.get(\"answer_text\") or str(c.get(\"value\") or \"\")) + \" \" + (c.get(\"unit\") or \"\")\n",
        "            try:\n",
        "                ce_answers.append(float(self._ce_score(question, answer_text.strip())))\n",
        "            except Exception:\n",
        "                ce_answers.append(0.0)\n",
        "\n",
        "        order = list(np.argsort(ce_evidences)[::-1]) if ce_evidences else []\n",
        "        top1 = ce_evidences[order[0]] if order else 0.0\n",
        "        top2 = ce_evidences[order[1]] if len(order) > 1 else 0.0\n",
        "        margin = float(top1 - top2)\n",
        "        std_ce = float(np.std(ce_evidences)) if len(ce_evidences) > 1 else 0.0\n",
        "\n",
        "        def close_count(idx, tol=0.5):\n",
        "            v = candidates[idx].get(\"value\")\n",
        "            if v is None: return 0\n",
        "            v = float(v); cnt = 0\n",
        "            for j, cj in enumerate(candidates):\n",
        "                if j == idx or cj.get(\"value\") is None: continue\n",
        "                if abs(float(cj[\"value\"]) - v) <= tol: cnt += 1\n",
        "            return cnt\n",
        "\n",
        "        def unit_onehots(u: str):\n",
        "            u = (u or \"\").lower()\n",
        "            return {\n",
        "                \"unit_%\": 1.0 if \"%\" in u else 0.0,\n",
        "                \"unit_ktco2e\": 1.0 if \"ktco2e\" in u else 0.0,\n",
        "                \"unit_tco2e\": 1.0 if \"tco2e\" in u else 0.0,\n",
        "                \"unit_gwh\": 1.0 if \"gwh\" in u else 0.0,\n",
        "                \"unit_mwh\": 1.0 if \"mwh\" in u else 0.0,\n",
        "                \"unit_m3\": 1.0 if re.search(r\"\\bm3\\b\", u) else 0.0,\n",
        "                \"unit_tonne\": 1.0 if re.search(r\"\\b(tonnes?|t)\\b\", u) else 0.0,\n",
        "            }\n",
        "\n",
        "        feats = []\n",
        "        for i, c in enumerate(candidates):\n",
        "            unit = c.get(\"unit\")\n",
        "            val = c.get(\"value\")\n",
        "            value_log10 = (math.log10(float(val)) if isinstance(val,(int,float)) and float(val)>0 else -10.0)\n",
        "            plausible = 1.0 if self._validate_value_generic(unit, val if isinstance(val,(int,float)) else None) else 0.0\n",
        "\n",
        "            yrs = [int(y) for y in re.findall(r\"\\b(20\\d{2})\\b\", evidences[i])]\n",
        "            year_in_evidence = max(yrs) if yrs else 0\n",
        "            now_year = 2025\n",
        "            recency_norm = max(0.0, min(1.0, (year_in_evidence - 2017) / (now_year - 2017 + 1))) if year_in_evidence else 0.0\n",
        "\n",
        "            row = {\n",
        "                \"kpi_source\": c.get(\"source\",\"\"),\n",
        "                \"value\": val,\n",
        "                \"unit\": unit,\n",
        "                \"ce_evidence\": float(ce_evidences[i]),\n",
        "                \"ce_answer\": float(ce_answers[i]),\n",
        "                \"ce_is_top\": 1.0 if (order and i == order[0]) else 0.0,\n",
        "                \"ce_margin_top1_top2\": margin,\n",
        "                \"std_ce_over_cands\": std_ce,\n",
        "                \"consensus_close_count\": close_count(i),\n",
        "                \"year_in_evidence\": year_in_evidence,\n",
        "                \"recency_norm\": recency_norm,\n",
        "                \"value_log10\": value_log10,\n",
        "                \"is_plausible\": plausible,\n",
        "                \"doc_type\": c.get(\"doc_type\",\"\"),\n",
        "                \"page\": c.get(\"page\"),\n",
        "                \"bbox\": c.get(\"bbox\"),\n",
        "                \"evidence_preview\": (c.get(\"evidence\",\"\") or c.get(\"reason\",\"\"))[:200],\n",
        "                \"y\": \"\"\n",
        "            }\n",
        "            row.update(unit_onehots(unit))\n",
        "            feats.append(row)\n",
        "        return feats\n",
        "\n",
        "    def _winner_meta(self, kpi_entry: dict) -> dict:\n",
        "        w = (kpi_entry or {}).get(\"winner\") or {}\n",
        "        return {\n",
        "            \"source\": w.get(\"source\"),\n",
        "            \"unit\": w.get(\"unit\"),\n",
        "            \"page\": w.get(\"page\"),\n",
        "            \"doc_type\": w.get(\"doc_type\"),\n",
        "            \"answer_text\": w.get(\"answer_text\"),\n",
        "            \"evidence\": w.get(\"evidence\"),\n",
        "            \"table_fp\": w.get(\"table_fp\") or w.get(\"fingerprint\"),\n",
        "            \"image_crop_path\": w.get(\"image_crop_path\"),\n",
        "            \"judge_confidence\": w.get(\"judge_confidence\"),\n",
        "            \"judge_reason\": w.get(\"judge_reason\"),\n",
        "        }\n",
        "\n",
        "\n",
        "    def _append_csv_rows(self, rows: list[dict], out_csv: str):\n",
        "        if not rows: return\n",
        "        header = []\n",
        "        seen = set()\n",
        "        for r in rows:\n",
        "            for k in r.keys():\n",
        "                if k not in seen:\n",
        "                    seen.add(k); header.append(k)\n",
        "        need_header = not os.path.exists(out_csv)\n",
        "        with open(out_csv, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            w = csv.DictWriter(f, fieldnames=header)\n",
        "            if need_header: w.writeheader()\n",
        "            for r in rows: w.writerow(r)\n",
        "\n",
        "\n",
        "    def _generate_text(self, system_msg: str, user_msg: str, max_new_tokens: int | None = None) -> str:\n",
        "        \"\"\"\n",
        "        Génère via ChatML. Laisse le modèle raisonner (<think>), puis on le strippera.\n",
        "        \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\",   \"content\": user_msg},\n",
        "        ]\n",
        "        prompt = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(self.device)\n",
        "\n",
        "        gen_kwargs = dict(\n",
        "            max_new_tokens=int(max_new_tokens or self.max_new_tokens_json),\n",
        "            no_repeat_ngram_size=0,\n",
        "            pad_token_id=self.tokenizer.pad_token_id,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            out = self.model.generate(**inputs, **gen_kwargs)\n",
        "\n",
        "        gen_ids = out[:, inputs[\"input_ids\"].shape[1]:]\n",
        "        raw = self.tokenizer.decode(gen_ids[0], skip_special_tokens=False).strip()\n",
        "        # on garde le raw (avec <think>) pour pouvoir le nettoyer après\n",
        "        return raw\n",
        "\n",
        "\n",
        "    def _strip_think(self, text: str) -> str:\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        s = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL|re.IGNORECASE)\n",
        "        # si une balise ouvrante subsiste sans fermeture, on coupe tout ce qui suit\n",
        "        low = s.lower()\n",
        "        if \"<think>\" in low and \"</think>\" not in low:\n",
        "            s = s[:low.rfind(\"<think>\")].strip()\n",
        "        # enlève les fences ```json ... ```\n",
        "        s = re.sub(r\"```[\\w-]*\\n?|```\", \"\", s).strip()\n",
        "        return s\n",
        "\n",
        "\n",
        "    def _summarize_controversies(self, contro_context: str) -> str:\n",
        "        \"\"\"\n",
        "        Résume les controverses en 1–2 phrases en utilisant la méthode de guidage standard.\n",
        "        \"\"\"\n",
        "        if not contro_context or not contro_context.strip():\n",
        "            return \"\"\n",
        "\n",
        "        format_json = '{\"controversy_comment\": \"<1–2 concise sentences>\"}'\n",
        "        # Prompt de \"guidage\"\n",
        "        system_msg = (\n",
        "            \"You are an ESG analyst. First, think in a <think> block to identify the key controversy. \"\n",
        "            \"Then, provide the summary as a single, compact JSON object and nothing else.\"\n",
        "        )\n",
        "        user_msg = f\"CONTRO_CONTEXT:\\n{contro_context}\\n\\nFINAL ANSWER FORMAT:\\n{format_json}\"\n",
        "\n",
        "        # Logique de génération standardisée\n",
        "        raw_output = self._generate_text(system_msg, user_msg, max_new_tokens=500)\n",
        "        final_answer = self._strip_think(raw_output)\n",
        "\n",
        "        # Essaie d'extraire le commentaire du JSON\n",
        "        js = self._extract_first_json_object(final_answer)\n",
        "        if js:\n",
        "            try:\n",
        "                obj = self._json_loads_lenient(js)\n",
        "                if obj and isinstance(obj, dict):\n",
        "                    comment = obj.get(\"controversy_comment\", \"\").strip()\n",
        "                    if comment:\n",
        "                        return comment\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Fallback: si pas de JSON valide, on retourne la réponse nettoyée comme meilleur effort\n",
        "        return final_answer\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Judge (Donut vs RAG)\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    def _llm_judge_candidates(self, question: str, unit_hint: str | None, candidates: list[dict]) -> dict | None:\n",
        "        \"\"\"\n",
        "        LLM-Judge (DeepSeek) : choisit le meilleur candidat parmi VQA (Donut) et RAG+LLM.\n",
        "        - Réduit la liste pour éviter la verbosité.\n",
        "        - Rend un JSON: {\"winner_index\": int, \"confidence\": float, \"reason\": \"...\"}.\n",
        "        - Fallback: retourne None si parsing impossible (le caller gère le repli heuristique).\n",
        "        \"\"\"\n",
        "        if not candidates:\n",
        "            return None\n",
        "\n",
        "        if len(candidates) == 1 and self._validate_value_generic(candidates[0].get('unit'), candidates[0].get('value')):\n",
        "            return candidates[0]\n",
        "\n",
        "        # 1) Réduction (max 4) : garder au plus 1 par source + top CE sur le reste\n",
        "        #    -> priorité: Donut + RAG ; sinon top-CE.\n",
        "        prio = []\n",
        "        seen_src = set()\n",
        "        # essaie d'abord de garder 1 Donut et 1 RAG\n",
        "        for src in (\"Donut-DocVQA\", \"RAG+LLM\"):\n",
        "            for i, c in enumerate(candidates):\n",
        "                if c.get(\"source\") == src and src not in seen_src:\n",
        "                    prio.append((i, c)); seen_src.add(src); break\n",
        "        # complète avec top-CE evidence sur le reste\n",
        "        rest = [(i, c) for i, c in enumerate(candidates) if c.get(\"source\") not in seen_src]\n",
        "        # score CE evidence rapide\n",
        "        scored_rest = []\n",
        "        for i, c in rest:\n",
        "            ev = \" \".join([(c.get(\"answer_text\") or \"\"), (c.get(\"reason\") or \"\"), (c.get(\"evidence\") or \"\")]).strip()\n",
        "            try:\n",
        "                s = float(self._ce_score(question, ev))\n",
        "            except Exception:\n",
        "                s = 0.0\n",
        "            scored_rest.append((s, i, c))\n",
        "        scored_rest.sort(key=lambda x: x[0], reverse=True)\n",
        "        for s, i, c in scored_rest[:2]:\n",
        "            prio.append((i, c))\n",
        "        # borne finale\n",
        "        prio = prio[:4]\n",
        "\n",
        "        # 2) Vue compacte envoyée au LLM\n",
        "        def _trim(x, n):\n",
        "            x = (x or \"\").replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
        "            return (x[:n] + \"…\") if len(x) > n else x\n",
        "\n",
        "        unit_hint_norm = (unit_hint or \"\").strip()\n",
        "        cand_view = []\n",
        "        for local_idx, (original_idx, c) in enumerate(prio):\n",
        "                cand_view.append({ \"idx\": local_idx,\n",
        "                                  \"src\": c.get(\"source\"),\n",
        "                                   \"value\": c.get(\"value\"),\n",
        "                                   \"unit\": c.get(\"unit\"),\n",
        "                                   \"year\": c.get(\"year\"),\n",
        "                                   \"answer\": _trim(c.get(\"answer_text\"), 250) })\n",
        "\n",
        "        # 3) Prompt LLM — consignes strictes + JSON unique\n",
        "        format_json = '{\"winner_index\": 0, \"confidence\": 0.9, \"reason\": \"Reason for choice.\"}'\n",
        "        system_msg = (\n",
        "            \"You are a meticulous ESG data auditor. Your task is to analyze several data candidates and select the single most accurate one. \"\n",
        "            \"First, think step-by-step inside a <think> block to evaluate the candidates based on the rules. \"\n",
        "            \"Then, after the </think> block, provide your final answer as a single, compact JSON object and nothing else.\"\n",
        "        )\n",
        "        rules = [\n",
        "            \"Prefer the most recent year.\",\n",
        "            \"Evidence from a table (VQA) with clear context is more reliable than text snippets (RAG).\",\n",
        "            \"Ensure the evidence semantically matches the question.\",\n",
        "            f\"A unit hint of '{unit_hint}' was provided; this is a strong indicator.\" if unit_hint else \"No unit hint was provided.\"\n",
        "        ]\n",
        "        user_msg = (\n",
        "            f\"QUESTION: \\\"{question}\\\"\\n\\n\"\n",
        "            f\"RULES:\\n- \" + \"\\n- \".join(rules) + \"\\n\\n\"\n",
        "            f\"CANDIDATES (use 'idx' for your choice):\\n{json.dumps(cand_view, indent=2, ensure_ascii=False)}\\n\\n\"\n",
        "            f\"Based on your analysis, provide your final choice in the following JSON format ONLY:\\n{format_json}\"\n",
        "        )\n",
        "\n",
        "        # 3. Générer, nettoyer, et parser\n",
        "        raw_output = self._generate_text(system_msg, user_msg, max_new_tokens=300)\n",
        "        final_answer = self._strip_think(raw_output)\n",
        "        js_str = self._extract_first_json_object(final_answer)\n",
        "        if not js_str: return None\n",
        "\n",
        "        try:\n",
        "            obj = self._json_loads_lenient(js_str)\n",
        "            if not isinstance(obj, dict) or \"winner_index\" not in obj: return None\n",
        "            wi = int(obj[\"winner_index\"])\n",
        "            if not (0 <= wi < len(prio)): return None\n",
        "        except (ValueError, TypeError):\n",
        "            return None\n",
        "\n",
        "        # 4. Retourner le candidat gagnant au format standard, enrichi par le jugement\n",
        "        _original_idx, winner = prio[wi]\n",
        "        winner[\"judge_reason\"] = obj.get(\"reason\", \"\")\n",
        "        winner[\"judge_confidence\"] = float(obj.get(\"confidence\", 0.0))\n",
        "        return winner\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # MAIN\n",
        "    # --------------------------------------------------------------------------\n",
        "    def run_full_analysis(self, document_paths: dict, force_preprocessing: bool = True):\n",
        "        import hashlib, os, gc, concurrent.futures as cf, torch\n",
        "\n",
        "        # 1) Clé de cache par PDF principal\n",
        "        main_report_path = document_paths.get(\"sustainability\") or document_paths.get(\"controversies\") or \"default\"\n",
        "        cache_prefix = hashlib.sha1(os.path.basename(main_report_path).encode()).hexdigest()[:10]\n",
        "\n",
        "        # 2) Fichiers de cache\n",
        "        self.cache_files = {\n",
        "            \"chunks\": os.path.join(self.cache_dir, f\"{cache_prefix}_chunks.json\"),\n",
        "            \"tables\": os.path.join(self.cache_dir, f\"{cache_prefix}_tables.pkl\"),\n",
        "            \"embeddings\": os.path.join(self.cache_dir, f\"{cache_prefix}_embeddings.npy\"),\n",
        "            \"bm25\": os.path.join(self.cache_dir, f\"{cache_prefix}_bm25.pkl\")\n",
        "        }\n",
        "\n",
        "        # 3) Purge ciblée (cache + crops images/<cache_prefix>) si forcing\n",
        "        self._purge_cache_artifacts(cache_prefix, force=force_preprocessing, phase=\"pre\")\n",
        "\n",
        "        # 4) Charger du cache ou refaire tout le préprocess\n",
        "        if (not force_preprocessing) and all(os.path.exists(p) for p in self.cache_files.values()):\n",
        "            print(\"\\n--- Found cached data. Loading from disk... ---\")\n",
        "            self._load_from_cache()\n",
        "        else:\n",
        "            print(\"\\n--- No valid cache found or preprocessing forced. Running full preprocessing... ---\")\n",
        "            self._preprocess_and_save_to_cache(document_paths)\n",
        "\n",
        "        # Prune PNG orphelins\n",
        "        self._purge_cache_artifacts(cache_prefix, force=False, phase=\"post\")\n",
        "\n",
        "\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Divers utilitaires JSON\n",
        "    # --------------------------------------------------------------------------\n",
        "    def _parse_llm_output(self, llm_output_str: str) -> dict:\n",
        "        llm_output_str = self._strip_think(llm_output_str or \"\")\n",
        "        json_candidate = self._extract_first_json_object(llm_output_str)\n",
        "        data = self._json_loads_lenient(json_candidate) if json_candidate else None\n",
        "\n",
        "        current_val = None\n",
        "        reasoning = \"JSON parsing failed or no JSON found.\"\n",
        "        is_present = False\n",
        "        unit = None\n",
        "        year = None\n",
        "\n",
        "        if isinstance(data, dict):\n",
        "            reasoning = data.get(\"reasoning\", reasoning)\n",
        "            current_val = self._coerce_float(data.get(\"current_value\"))\n",
        "            unit = data.get(\"unit\")\n",
        "            y = data.get(\"year\")\n",
        "            if isinstance(y, (int, float)): year = int(y)\n",
        "            elif isinstance(y, str):\n",
        "                m = re.search(r\"\\b20\\D?(\\d{2})\\b\", y);  # capte \"20,24\" etc.\n",
        "                if m: year = int(\"20\" + m.group(1))\n",
        "            is_present = bool(data.get(\"is_present\", current_val is not None))\n",
        "\n",
        "        # Fallback si pas de JSON exploitable: tenter de repêcher la valeur dans le texte\n",
        "        if current_val is None:\n",
        "            rescued = self._guess_current_from_text(llm_output_str)\n",
        "            if rescued is not None:\n",
        "                current_val = rescued\n",
        "                is_present = True\n",
        "\n",
        "        return {\"current\": current_val, \"reasoning\": reasoning, \"is_present\": is_present, \"unit\": unit, \"year\": year}\n",
        "\n",
        "\n",
        "    def _extract_first_json_object(self, text: str) -> str | None:\n",
        "        start = text.find(\"{\")\n",
        "        if start == -1: return None\n",
        "        depth = 0; in_str = False; esc = False\n",
        "        for i in range(start, len(text)):\n",
        "            ch = text[i]\n",
        "            if ch == '\"' and not esc:\n",
        "                in_str = not in_str\n",
        "            esc = (ch == \"\\\\\") and not esc if in_str else False\n",
        "            if in_str: continue\n",
        "            if ch == \"{\": depth += 1\n",
        "            elif ch == \"}\":\n",
        "                depth -= 1\n",
        "                if depth == 0: return text[start : i + 1]\n",
        "        return None\n",
        "\n",
        "    def _json_loads_lenient(self, s: str) -> dict | None:\n",
        "        if not s:\n",
        "            return None\n",
        "        s1 = s.strip()\n",
        "        # 1) virer les fences\n",
        "        s1 = re.sub(r\"```[\\w-]*\\n?|```\", \"\", s1)\n",
        "        # 2) guillemets typographiques → ASCII\n",
        "        s1 = s1.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\")\n",
        "        # 3) quoter les clés non-quotées: key: val -> \"key\": val\n",
        "        #    (heuristique raisonnable hors chaînes)\n",
        "        s1 = re.sub(r'(?<!\")\\b([A-Za-z_][A-Za-z0-9_]*)\\b\\s*:', r'\"\\1\":', s1)\n",
        "        # 4) supprimer virgules avant } ou ]\n",
        "        s1 = re.sub(r\",\\s*(?=[}\\]])\", \"\", s1)\n",
        "        # 5) Python→JSON\n",
        "        s1 = s1.replace(\"None\", \"null\").replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
        "        try:\n",
        "            return json.loads(s1)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def _guess_current_from_text(self, text: str) -> float | None:\n",
        "        m = re.search(r\"current[_\\s-]?value\\s*[:=]\\s*([0-9][0-9\\.,_ ]*)\", text, flags=re.IGNORECASE)\n",
        "        if m: return self._coerce_float(m.group(1))\n",
        "        m = re.search(r\"(current year|current|latest|most recent)\\D{0,40}([0-9][0-9\\.,_ ]*)\", text, flags=re.IGNORECASE)\n",
        "        if m: return self._coerce_float(m.group(2))\n",
        "        fy = re.findall(r\"FY\\s*([12][0-9]{3})\", text, flags=re.IGNORECASE)\n",
        "        if fy:\n",
        "            fy_latest = max(map(int, fy))\n",
        "            window = 120\n",
        "            for m in re.finditer(r\"FY\\s*([12][0-9]{3})\", text, flags=re.IGNORECASE):\n",
        "                if int(m.group(1)) == fy_latest:\n",
        "                    start = max(0, m.start() - window); end = min(len(text), m.end() + window)\n",
        "                    near = text[start:end]; n = re.search(r\"([0-9][0-9\\.,_ ]*)\", near)\n",
        "                    if n:\n",
        "                        val = self._coerce_float(n.group(1))\n",
        "                        if val is not None: return val\n",
        "        m = re.search(r\"([0-9][0-9\\.,_ ]*)\\s*(ktco2e|twh|%|m3|tonnes|tons|t)\\b\", text, flags=re.IGNORECASE)\n",
        "        if m: return self._coerce_float(m.group(1))\n",
        "        m = re.search(r\"\\b([0-9][0-9\\.,_]{2,})\\b\", text)\n",
        "        if m: return self._coerce_float(m.group(1))\n",
        "        return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O4DqKyMzdbD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT .py"
      ],
      "metadata": {
        "id": "eorNX4HulU7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/esg_rating_project\"\n",
        "# D) Se placer dans le répertoire du projet et installer votre code\n",
        "print(f\"\\n--- Installation du package local 'esg_rating_engine' depuis {PROJECT_ROOT} ---\")\n",
        "os.chdir(PROJECT_ROOT)\n",
        "# L'option '-q' rend l'installation silencieuse\n",
        "!pip install -q -e .\n",
        "\n",
        "print(\"\\n\\n✅ --- ENVIRONNEMENT DE PROJET PRÊT --- ✅\")"
      ],
      "metadata": {
        "id": "FH76u3Y4XoIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN DOC PREPROCESSING"
      ],
      "metadata": {
        "id": "ttDowqzMwFsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CELLULE 4: LANCEMENT DE L'ANALYSE\n",
        "# ==============================================================================\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "# S'assurer que le répertoire de travail est bien celui du projet\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/esg_rating_project\"\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "# Importer la classe principale maintenant que le package est installé\n",
        "from src.esg_engine import ESGRatingEngine\n",
        "\n",
        "print(\"=============================================\")\n",
        "print(\"=           PREPROCESSING DOCUMENT          =\")\n",
        "print(\"=============================================\")\n",
        "\n",
        "# Définir les chemins des rapports à analyser\n",
        "reports_directory = \"data/reports_to_analyze\"\n",
        "company_name = \"Strauss Group\"\n",
        "sustainability_report_path = os.path.join(reports_directory, \"PPF.pdf\") # Assurez-vous que le fichier est sur votre Drive\n",
        "controversies_report_path = os.path.join(reports_directory, \"PPF controversy.pdf\")\n",
        "\n",
        "# Logique de lancement...\n",
        "document_paths = {'sustainability': sustainability_report_path, 'financial': None, 'controversies': controversies_report_path}\n",
        "\n",
        "\n",
        "try:\n",
        "    engine = ESGRatingEngine()\n",
        "    final_rating = engine.run_full_analysis(document_paths)\n",
        "    print(\"\\n\\n--- RAPPORT FINAL ---\")\n",
        "    print(json.dumps(final_rating, indent=2))\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\nUNE ERREUR CRITIQUE EST SURVENUE DURANT L'ANALYSE.\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "pwY_A581lOwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KPI Extraction"
      ],
      "metadata": {
        "id": "-y5zJJPfVFKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [1/3] === RAG + Extraction → enregistrement structuré des résultats (results_df) ===\n",
        "import os, re, json, hashlib, numpy as np, faiss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.append(os.getcwd())\n",
        "\n",
        "from src.esg_engine import ESGRatingEngine\n",
        "from src.kpi_config import KPI_FRAMEWORK\n",
        "from datetime import datetime\n",
        "\n",
        "# -------------------- PARAMS (reprise) --------------------\n",
        "ALL_KPIS = [\n",
        "    (pillar, kpi_name)\n",
        "    for pillar, kpis in KPI_FRAMEWORK.items()\n",
        "    for kpi_name in kpis.keys()\n",
        "]\n",
        "TOP_K_RAG_CONTEXTS = 3\n",
        "GEN_BUDGET = 512\n",
        "SHOW_RAW_FULL = False\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def _auto_paths():\n",
        "    root = os.environ.get(\"ESG_PROJECT_ROOT\", \"/content/drive/MyDrive/esg_rating_project\")\n",
        "    reports_dir = os.path.join(root, \"data\", \"reports_to_analyze\")\n",
        "    sust = os.path.join(reports_dir, \"PPF.pdf\")\n",
        "    contro = os.path.join(reports_dir, \"PPF controversy.pdf\")\n",
        "    return {\"sustainability\": sust if os.path.exists(sust) else None,\n",
        "            \"financial\": None, \"controversies\": contro if os.path.exists(contro) else None}\n",
        "\n",
        "print(\"CHEMINS DES DOCUMENTS:\", _auto_paths())\n",
        "eng = ESGRatingEngine()\n",
        "\n",
        "# ---- Cache ----\n",
        "main_report_path = _auto_paths().get(\"sustainability\") or \"default\"\n",
        "cache_prefix = hashlib.sha1(os.path.basename(main_report_path).encode()).hexdigest()[:10]\n",
        "eng.cache_files = {\n",
        "    \"chunks\": os.path.join(eng.cache_dir, f\"{cache_prefix}_chunks.json\"),\n",
        "    \"tables\": os.path.join(eng.cache_dir, f\"{cache_prefix}_tables.pkl\"),\n",
        "    \"embeddings\": os.path.join(eng.cache_dir, f\"{cache_prefix}_embeddings.npy\"),\n",
        "    \"bm25\": os.path.join(eng.cache_dir, f\"{cache_prefix}_bm25.pkl\"),\n",
        "}\n",
        "if all(os.path.exists(p) for p in eng.cache_files.values()):\n",
        "    print(\"[DEBUG] Chargement depuis le cache…\"); eng._load_from_cache()\n",
        "else:\n",
        "    raise RuntimeError(\"Cache manquant. Lancez preprocessing(..., force_preprocessing=True) d'abord.\")\n",
        "\n",
        "# ---- Infos LLM (lecture seule)\n",
        "tok, model = eng.tokenizer, eng.model\n",
        "tpl = (tok.chat_template or \"\")\n",
        "print(\"\\n[LLM/Tokenizer INFO]\")\n",
        "print(\"  • Model:\", type(model).__name__)\n",
        "print(\"  • Device:\", eng.device)\n",
        "print(\"  • engine.max_new_tokens_json:\", eng.max_new_tokens_json)\n",
        "print(\"  • eos_token_id:\", tok.eos_token_id, \"| pad_token_id:\", tok.pad_token_id)\n",
        "print(\"  • ChatML présent ?\",\n",
        "      (\"<|im_start|>\" in str(tpl) and \"<|im_end|>\" in str(tpl)))\n",
        "\n",
        "# ============ Format de sortie LLM (inchangé) ============\n",
        "JSON_FORMAT = '{\"reasoning\":\"<short evidence>\", \"current_value\": 1234.5, \"unit\": \"tCO2e|tons|m3|null\", \"year\": 2024, \"is_present\": true}'\n",
        "STRICT_RULES = (\n",
        "    \"Rules:\\n\"\n",
        "    \"1) If you cannot find an explicit number for the QUESTION in CONTEXT, return exactly: \"\n",
        "    '{\"reasoning\":\"not found\", \"current_value\": null, \"unit\": null, \"year\": null, \"is_present\": false}\\n'\n",
        "    \"2) Copy digits **verbatim** from CONTEXT. Do not reorder, do not guess. If you write 15,571 in reasoning, current_value must be 15571 (commas/spaces removed).\\n\"\n",
        "    \"3) Year must be a 4-digit year **seen in CONTEXT near the value**.\\n\"\n",
        "    \"4) Output ONE JSON object only. First char must be '{'. No extra text.\"\n",
        ")\n",
        "SYS_THINK = (\n",
        "    \"You are a precise data extraction expert.\\n\"\n",
        "    \"First, think step-by-step inside a <think> block (≤60 tokens) to locate the number *in the CONTEXT*.\\n\"\n",
        "    \"Then output exactly ONE JSON object and nothing else.\\n\" + STRICT_RULES\n",
        ")\n",
        "def _strip_think(s: str) -> str:\n",
        "    return re.sub(r\"<think>.*?</think>\", \"\", s, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "\n",
        "_num_pat  = re.compile(r\"\\b\\d{1,3}(?:[ ,.\\u00A0]\\d{3})*(?:[.,]\\d+)?\\b\")\n",
        "_year_pat = re.compile(r\"\\b20\\d{2}\\b\")\n",
        "def _numbers_in_ctx(ctx):\n",
        "    spans = _num_pat.findall(ctx)\n",
        "    def norm(x):\n",
        "        return float(re.sub(r\"[,\\s\\u00A0]\", \"\", x).replace(\" \", \"\"))\n",
        "    values = []\n",
        "    for s in spans:\n",
        "        try:\n",
        "            v = norm(s)\n",
        "            values.append((s, v))\n",
        "        except:\n",
        "            pass\n",
        "    return values\n",
        "def _sanity_check(ctx, parsed):\n",
        "    ok = True\n",
        "    reasons = []\n",
        "    cv = parsed.get(\"current\")\n",
        "    yr = parsed.get(\"year\")\n",
        "    unit = parsed.get(\"unit\")\n",
        "    if cv is None:\n",
        "        return False, [\"no current_value\"]\n",
        "    vals = _numbers_in_ctx(ctx)\n",
        "    present_nums = {v for _, v in vals}\n",
        "    if cv not in present_nums:\n",
        "        if unit == \"ktCO2e\" and (cv*1000) in present_nums:\n",
        "            pass\n",
        "        elif unit == \"tCO2e\" and (cv/1000) in present_nums:\n",
        "            pass\n",
        "        else:\n",
        "            ok = False; reasons.append(\"value_not_in_context\")\n",
        "    if unit not in (None, \"tCO2e\", \"ktCO2e\"):\n",
        "        ok = False; reasons.append(\"bad_unit\")\n",
        "    if yr is not None and not _year_pat.search(ctx):\n",
        "        ok = False; reasons.append(\"year_not_in_context\")\n",
        "    return ok, reasons\n",
        "\n",
        "def _run(engine, ctx_text, question, sys_msg, label):\n",
        "    user_msg = f\"CONTEXT:\\n{ctx_text}\\n\\nQUESTION: {question}\\n\\nFINAL ANSWER FORMAT:\\n{JSON_FORMAT}\"\n",
        "    raw = engine._generate_text(sys_msg, user_msg, max_new_tokens=GEN_BUDGET)\n",
        "    final = _strip_think(raw)\n",
        "    js = engine._extract_first_json_object(final)\n",
        "    parsed = engine._parse_llm_output(js or final)\n",
        "\n",
        "    preview = raw if SHOW_RAW_FULL else (raw[:240] + \"…\") if len(raw) > 240 else raw\n",
        "    print(f\"\\n[{label}] RAW:\", preview or \"(empty)\")\n",
        "    print(f\"[{label}] found_json={bool(js)}\")\n",
        "    if js: print(f\"[{label}] JSON:\", js)\n",
        "    print(f\"[{label}] PARSED:\", parsed)\n",
        "\n",
        "    ok_digits, why = _sanity_check(ctx_text, parsed)\n",
        "    if not ok_digits:\n",
        "        print(f\"[{label}] SANITY: FAIL ->\", why)\n",
        "    else:\n",
        "        print(f\"[{label}] SANITY: OK\")\n",
        "    val = parsed.get(\"current\")\n",
        "    ok_schema = (val is not None) and eng._validate_value_generic(None, val)\n",
        "    return (ok_digits and ok_schema), parsed\n",
        "\n",
        "# -------------------- RUN & CAPTURE --------------------\n",
        "rows = []\n",
        "docs_paths = _auto_paths()\n",
        "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "for pillar, kpi_name in ALL_KPIS:\n",
        "    kpi_cfg = KPI_FRAMEWORK[pillar][kpi_name]\n",
        "    question_long = kpi_cfg.get(\"question\", kpi_name)\n",
        "    search_query  = kpi_cfg.get(\"search_query\", question_long)\n",
        "\n",
        "    print(f\"\\n===== KPI: {pillar} - {kpi_name} =====\")\n",
        "    print(\"Question (extraction):\", question_long)\n",
        "    print(\"Search Query (retrieval):\", search_query)\n",
        "\n",
        "    allowed_docs = {\"controversies\"} if pillar == \"C\" else {\"sustainability\"}\n",
        "\n",
        "    indices = []\n",
        "    if eng.bm25_index is not None and eng.chunks:\n",
        "        toks = [t for t in search_query.lower().split() if t]\n",
        "        bm_scores = eng.bm25_index.get_scores(toks)\n",
        "        bm_top = np.argsort(bm_scores)[::-1][:eng.rag_top_candidates]\n",
        "        indices.extend(bm_top.tolist())\n",
        "\n",
        "    if eng.faiss_index is not None and eng.all_embeddings is not None:\n",
        "        import faiss\n",
        "        q = eng.embedding_model.encode([search_query], convert_to_numpy=True)\n",
        "        q = np.ascontiguousarray(q, dtype=np.float32)\n",
        "        faiss.normalize_L2(q)\n",
        "        _, fa_top = eng.faiss_index.search(q, eng.rag_top_candidates)\n",
        "        indices.extend(fa_top[0].tolist())\n",
        "\n",
        "    # dédup & filtre type doc\n",
        "    indices = list(dict.fromkeys(indices))\n",
        "    if allowed_docs:\n",
        "        indices = [i for i in indices if eng.chunk_doc_types[i] in allowed_docs]\n",
        "\n",
        "    if not indices:\n",
        "        print(\"→ Aucun contexte admissible après filtrage (docs autorisés).\")\n",
        "        # On logge malgré tout un \"candidat vide\" pour traçabilité\n",
        "        rows.append({\n",
        "            \"pillar\": pillar, \"kpi\": kpi_name, \"question\": question_long, \"search_query\": search_query,\n",
        "            \"variant\": \"with-think / search_query\", \"context_rank\": None,\n",
        "            \"chunk_id\": None, \"doc_type\": \",\".join(sorted(allowed_docs)), \"doc_path\": None,\n",
        "            \"ok\": False, \"sanity_ok\": False, \"sanity_why\": \"no_context\",\n",
        "            \"value\": None, \"unit\": None, \"year\": None, \"is_present\": False,\n",
        "            \"reasoning\": \"no admissible context after filtering\", \"ctx_preview\": \"\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    top_ids = eng._rerank_doc_ids(search_query, indices, top_k=TOP_K_RAG_CONTEXTS)\n",
        "    print(\"\\n--- [DIAGNOSTIC RAG] Contexte sélectionné ---\")\n",
        "    print(f\"-> {len(top_ids)} chunk(s) : {top_ids}\")\n",
        "    for i, cid in enumerate(top_ids, 1):\n",
        "        doc_t = eng.chunk_doc_types[cid]\n",
        "        preview = eng.chunks[cid][:500].replace(\"\\n\", \" \")\n",
        "        print(f\"  [Chunk {i} | id={cid} | doc={doc_t}] {preview}…\")\n",
        "\n",
        "    # ---- Lancement (variante with-think / search_query) ----\n",
        "    for rank, idx in enumerate(top_ids, 1):\n",
        "        ctx = eng.chunks[idx]\n",
        "        print(f\"\\n\\n===== CONTEXTE #{rank} (id={idx}, doc={eng.chunk_doc_types[idx]}) =====\")\n",
        "        print(\"PREVIEW:\", (ctx[:300] + \"…\") if len(ctx) > 300 else ctx)\n",
        "\n",
        "        ok, parsed = _run(eng, ctx, search_query, SYS_THINK, \"with-think / search_query\")\n",
        "        sanity_ok, why = _sanity_check(ctx, parsed)\n",
        "\n",
        "        rows.append({\n",
        "            \"pillar\": pillar,\n",
        "            \"kpi\": kpi_name,\n",
        "            \"question\": question_long,\n",
        "            \"search_query\": search_query,\n",
        "            \"variant\": \"with-think / search_query\",\n",
        "            \"context_rank\": rank,\n",
        "            \"chunk_id\": idx,\n",
        "            \"doc_type\": eng.chunk_doc_types[idx],\n",
        "            \"doc_path\": docs_paths.get(eng.chunk_doc_types[idx]),\n",
        "            \"ok\": bool(ok),\n",
        "            \"sanity_ok\": bool(sanity_ok),\n",
        "            \"sanity_why\": \";\".join(why) if not sanity_ok else \"\",\n",
        "            \"value\": parsed.get(\"current\"),\n",
        "            \"unit\": parsed.get(\"unit\"),\n",
        "            \"year\": parsed.get(\"year\"),\n",
        "            \"is_present\": parsed.get(\"is_present\"),\n",
        "            \"reasoning\": parsed.get(\"reasoning\"),\n",
        "            \"ctx_preview\": ctx[:600].replace(\"\\n\", \" \"),\n",
        "        })\n",
        "\n",
        "# ---- DataFrame & sauvegarde ----\n",
        "results_df = pd.DataFrame(rows)\n",
        "RES_DIR = os.path.join(eng.cache_dir, \"human_in_the_loop\")\n",
        "os.makedirs(RES_DIR, exist_ok=True)\n",
        "base_fname = f\"extractions_{cache_prefix}_{RUN_ID}\"\n",
        "csv_path = os.path.join(RES_DIR, base_fname + \".csv\")\n",
        "parq_path = os.path.join(RES_DIR, base_fname + \".parquet\")\n",
        "results_df.to_csv(csv_path, index=False)\n",
        "try:\n",
        "    results_df.to_parquet(parq_path, index=False)\n",
        "except Exception as e:\n",
        "    print(f\"[WARN] Parquet non écrit ({e}). CSV disponible.\")\n",
        "\n",
        "print(f\"\\n[OK] {len(results_df)} candidats enregistrés →\")\n",
        "print(\"     \", csv_path)\n",
        "print(\"     \", parq_path if os.path.exists(parq_path) else \"(parquet non écrit)\")\n",
        "\n",
        "# Garder en mémoire pour la cellule UI\n",
        "print(\"\\nresults_df.head():\")\n",
        "display(results_df.head())\n"
      ],
      "metadata": {
        "id": "FKXLHJYGSOjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human in the loop"
      ],
      "metadata": {
        "id": "HR8ASGDHbVyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  [2/3] === UI de revue & sélection par KPI → DataFrame features prêt pour le modèle ===\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as w\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# --------- Charger les résultats (si non présents en mémoire) ----------\n",
        "if \"results_df\" not in globals() or results_df is None or results_df.empty:\n",
        "    # On tente de reprendre le dernier fichier d'extractions\n",
        "    import glob\n",
        "    RES_DIR = os.path.join(eng.cache_dir, \"human_in_the_loop\")\n",
        "    candidates = sorted(glob.glob(os.path.join(RES_DIR, \"extractions_*.csv\")))\n",
        "    assert candidates, \"Aucun fichier d'extractions trouvé. Exécutez d'abord la cellule [1/3].\"\n",
        "    latest_csv = candidates[-1]\n",
        "    results_df = pd.read_csv(latest_csv)\n",
        "    print(f\"[INFO] results_df chargé depuis {latest_csv} ({len(results_df)} lignes)\")\n",
        "\n",
        "# --------- Colonnes features attendues par le modèle (à adapter si besoin) ----------\n",
        "FEATURE_COLS_TARGET = [\n",
        "    \"ISSUER_CNTRY_DOMICILE\",\n",
        "    \"CARBON_EMISSIONS_SCOPE_1\",\n",
        "    \"CARBON_EMISSIONS_SCOPE_2\",\n",
        "    \"CARBON_EMISSIONS_SCOPE_3\",\n",
        "    \"PCT_NONRENEW_CONSUMP_PROD\",\n",
        "    \"HAZARD_WASTE_METRIC_TON\",\n",
        "    \"WATER_FRESH_CON\",\n",
        "    \"EMP_TURNOVER_ANNUAL_PCT_RECENT\",\n",
        "    \"TRIR\",\n",
        "    \"HLTH_SAFETY_FATALITIES_YEAR_RECENT\",\n",
        "    \"WOMEN_EXEC_MGMT_RECENT\",\n",
        "    \"FEMALE_DIRECTORS_PCT\",\n",
        "    \"BOARD_INDEP_PCT\",\n",
        "    \"PROF_DEV_TRAIN_HOURS_PER_EMP_RECENT\",\n",
        "    \"ENVIRONMENT_CONTROVERSY_SCORE\",\n",
        "    \"CUSTOMER_CONTROVERSY_SCORE\",\n",
        "    \"HUMAN_RIGHTS_CONTROVERSY_SCORE\",\n",
        "    \"LABOR_RIGHTS_CONTROVERSY_SCORE\",\n",
        "    \"GOVERNANCE_CONTROVERSY_SCORE\",\n",
        "    \"IVA_INDUSTRY\",\n",
        "]\n",
        "\n",
        "# --------- Mapping par défaut (à ajuster à vos clés KPI_FRAMEWORK) ----------\n",
        "# Astuce : la UI permet de re-mapper KPI→feature au besoin\n",
        "KPI_TO_FEATURE_COL = {\n",
        "    \"scope_1_emissions\": \"CARBON_EMISSIONS_SCOPE_1\",\n",
        "    \"scope_2_emissions\": \"CARBON_EMISSIONS_SCOPE_2\",\n",
        "    \"scope_3_emissions\": \"CARBON_EMISSIONS_SCOPE_3\",\n",
        "    \"hazardous_waste\": \"HAZARD_WASTE_METRIC_TON\",\n",
        "    \"renewable_energy_pct\":\"PCT_NONRENEW_CONSUMP_PROD\",\n",
        "    \"hazardous_waste\": \"HAZARD_WASTE_METRIC_TON\",\n",
        "    \"water_fresh_consumption\": \"WATER_FRESH_CON\",\n",
        "    \"employee_turnover_rate\": \"EMP_TURNOVER_ANNUAL_PCT_RECENT\",\n",
        "    \"trir\": \"TRIR\",\n",
        "    \"health_safety_fatalities\": \"HLTH_SAFETY_FATALITIES_YEAR_RECENT\",\n",
        "    \"women_exec_mgmt\": \"WOMEN_EXEC_MGMT_RECENT\",\n",
        "    \"female_directors_pct\": \"FEMALE_DIRECTORS_PCT\",\n",
        "    \"board_independence_pct\": \"BOARD_INDEP_PCT\",\n",
        "    \"training_hours_per_emp\": \"PROF_DEV_TRAIN_HOURS_PER_EMP_RECENT\",\n",
        "    \"env_controversy_score\": \"ENVIRONMENT_CONTROVERSY_SCORE\",\n",
        "    \"customers_controversy_score\": \"CUSTOMER_CONTROVERSY_SCORE\",\n",
        "    \"human_rights_community_controversy_score\": \"HUMAN_RIGHTS_CONTROVERSY_SCORE\",\n",
        "    \"labor_rights_supply_chain_controversy_score\": \"LABOR_RIGHTS_CONTROVERSY_SCORE\",\n",
        "    \"governance_controversy_score\": \"GOVERNANCE_CONTROVERSY_SCORE\",\n",
        "}\n",
        "\n",
        "# Fonction heuristique simple si une clé n'est pas mappée\n",
        "def guess_feature_col_from_kpi(k):\n",
        "    k_low = str(k).lower()\n",
        "    if \"scope_1\" in k_low: return \"CARBON_EMISSIONS_SCOPE_1\"\n",
        "    if \"scope_2\" in k_low: return \"CARBON_EMISSIONS_SCOPE_2\"\n",
        "    if \"scope_3\" in k_low: return \"CARBON_EMISSIONS_SCOPE_3\"\n",
        "    if \"renewable\" in k_low: return \"PCT_NONRENEW_CONSUMP_PROD\"\n",
        "    if \"waste\" in k_low: return \"HAZARD_WASTE_METRIC_TON\"\n",
        "    if \"water\" in k_low: return \"WATER_FRESH_CON\"\n",
        "    if \"turnover\" in k_low: return \"EMP_TURNOVER_ANNUAL_PCT_RECENT\"\n",
        "    if \"trir\" in k_low: return \"TRIR\"\n",
        "    if \"fatal\" in k_low: return \"HLTH_SAFETY_FATALITIES_YEAR_RECENT\"\n",
        "    if \"women\" in k_low and (\"exec\" in k_low or \"management\" in k_low): return \"WOMEN_EXEC_MGMT_RECENT\"\n",
        "    if \"female\" in k_low and \"director\" in k_low: return \"FEMALE_DIRECTORS_PCT\"\n",
        "    if \"indep\" in k_low: return \"BOARD_INDEP_PCT\"\n",
        "    if \"train\" in k_low: return \"PROF_DEV_TRAIN_HOURS_PER_EMP_RECENT\"\n",
        "    if \"env\" in k_low and \"controvers\" in k_low: return \"ENVIRONMENT_CONTROVERSY_SCORE\"\n",
        "    if \"customer\" in k_low and \"controvers\" in k_low: return \"CUSTOMER_CONTROVERSY_SCORE\"\n",
        "    if \"human\" in k_low and \"right\" in k_low: return \"HUMAN_RIGHTS_CONTROVERSY_SCORE\"\n",
        "    if \"labor\" in k_low or \"labour\" in k_low: return \"LABOR_RIGHTS_CONTROVERSY_SCORE\"\n",
        "    if \"governance\" in k_low and \"controvers\" in k_low: return \"GOVERNANCE_CONTROVERSY_SCORE\"\n",
        "    return None\n",
        "\n",
        "# --------- Préparation des groupes KPI ---------\n",
        "results_df[\"kpi_key\"] = results_df[\"kpi\"].astype(str)\n",
        "kpi_list = (\n",
        "    results_df[[\"pillar\",\"kpi_key\"]]\n",
        "    .drop_duplicates()\n",
        "    .sort_values([\"pillar\",\"kpi_key\"])\n",
        "    .values.tolist()\n",
        ")\n",
        "kpi_options = [f\"{p} • {k}\" for p, k in kpi_list]\n",
        "kpi_index_by_label = {f\"{p} • {k}\": (p,k) for p,k in kpi_list}\n",
        "\n",
        "# --------- Widgets header (métadonnées) ---------\n",
        "HTML(\"\"\"\n",
        "<style>\n",
        ".hitl-card { border:1px solid #e5e7eb; border-radius:10px; padding:12px; margin:8px 0; background:#fafafa; }\n",
        ".hitl-title { font-weight:600; font-size:16px; }\n",
        ".small { color:#6b7280; font-size:12px; }\n",
        ".ok-badge { background:#10b981; color:white; padding:2px 8px; border-radius:999px; font-size:11px; }\n",
        ".warn-badge { background:#f59e0b; color:white; padding:2px 8px; border-radius:999px; font-size:11px; }\n",
        ".err-badge { background:#ef4444; color:white; padding:2px 8px; border-radius:999px; font-size:11px; }\n",
        "</style>\n",
        "\"\"\")\n",
        "\n",
        "issuer_input = w.Text(description=\"Entreprise\", placeholder=\"Nom de l'émetteur\", layout=w.Layout(width=\"40%\"))\n",
        "country_input = w.Text(description=\"ISSUER_CNTRY_DOMICILE\", placeholder=\"FR, DE, US…\", layout=w.Layout(width=\"40%\"))\n",
        "sector_input  = w.Text(description=\"IVA_INDUSTRY *\", placeholder=\"Secteur (obligatoire)\", layout=w.Layout(width=\"40%\"))\n",
        "\n",
        "header_box = w.HBox([issuer_input, country_input, sector_input])\n",
        "\n",
        "# --------- Widgets KPI selector ---------\n",
        "kpi_select = w.Dropdown(options=kpi_options, description=\"KPI\", layout=w.Layout(width=\"60%\"))\n",
        "missing_value = w.Checkbox(value=False, description=\"Valeur manquante (NaN)\", disabled=True)\n",
        "# --------- Zone table candidats ---------\n",
        "table_out = w.Output(layout={\"border\":\"1px solid #e5e7eb\"})\n",
        "\n",
        "# --------- Widgets sélection / saisie ---------\n",
        "radio_candidates = w.RadioButtons(description=\"Candidats\", options=[], layout=w.Layout(width=\"100%\"))\n",
        "use_custom = w.Checkbox(value=False, description=\"Saisir une valeur manuellement\")\n",
        "val_input  = w.FloatText(description=\"Valeur\", disabled=True)\n",
        "unit_input = w.Text(description=\"Unité\", disabled=True)\n",
        "year_input = w.IntText(description=\"Année\", disabled=True)\n",
        "isp_input  = w.Checkbox(description=\"Présence (is_present)\", value=True, disabled=True)\n",
        "reas_input = w.Textarea(description=\"Reasoning\", layout=w.Layout(width=\"100%\", height=\"70px\"), disabled=True)\n",
        "\n",
        "# mapping KPI -> colonne feature\n",
        "feature_dropdown = w.Dropdown(\n",
        "    options=FEATURE_COLS_TARGET,\n",
        "    description=\"Colonne feature\",\n",
        "    layout=w.Layout(width=\"50%\")\n",
        ")\n",
        "\n",
        "save_btn = w.Button(description=\"Valider ce KPI\", button_style=\"success\", icon=\"check\")\n",
        "status_out = w.Output()\n",
        "\n",
        "# --------- Résumé & export ---------\n",
        "summary_out = w.Output()\n",
        "export_btn = w.Button(description=\"Exporter ➜ df_features_ready\", button_style=\"primary\", icon=\"save\")\n",
        "audit_out = w.Output()\n",
        "\n",
        "# --------- État sélectionné en mémoire ---------\n",
        "selected_map = {}  # (pillar,kpi_key) -> dict(value, unit, year, is_present, reasoning, feature_col, source_row)\n",
        "\n",
        "def _rank_candidates(dfk):\n",
        "    # Tri : ok DESC, sanity_ok DESC, is_present DESC, context_rank ASC\n",
        "    cols_present = {c for c in [\"ok\",\"sanity_ok\",\"is_present\",\"context_rank\"] if c in dfk.columns}\n",
        "    if {\"ok\",\"sanity_ok\",\"is_present\",\"context_rank\"} <= cols_present:\n",
        "        return dfk.sort_values([\"ok\",\"sanity_ok\",\"is_present\",\"context_rank\"],\n",
        "                               ascending=[False, False, False, True]).reset_index(drop=True)\n",
        "    return dfk.reset_index(drop=True)\n",
        "\n",
        "def refresh_candidates(_=None):\n",
        "    status_out.clear_output()\n",
        "    table_out.clear_output()\n",
        "    radio_candidates.options = []\n",
        "    val_input.disabled = unit_input.disabled = year_input.disabled = isp_input.disabled = reas_input.disabled = not use_custom.value\n",
        "    missing_value.disabled = (not use_custom.value)  # AJOUT\n",
        "\n",
        "    p,k = kpi_index_by_label[kpi_select.value]\n",
        "    dfk = results_df[(results_df[\"pillar\"]==p) & (results_df[\"kpi_key\"]==k)].copy()\n",
        "    if dfk.empty:\n",
        "        with table_out:\n",
        "            display(HTML(f\"<div class='hitl-card'><span class='err-badge'>VIDE</span> Aucun candidat pour {p} • {k}</div>\"))\n",
        "        return\n",
        "\n",
        "    dfk = _rank_candidates(dfk)\n",
        "    # Affichage compact\n",
        "    with table_out:\n",
        "        display(HTML(f\"<div class='hitl-card'><div class='hitl-title'>Candidats pour <b>{p} • {k}</b></div>\"\n",
        "                     f\"<div class='small'>Triés par qualité puis rang de contexte</div></div>\"))\n",
        "        display(dfk[[\"context_rank\",\"value\",\"unit\",\"year\",\"is_present\",\"ok\",\"sanity_ok\",\"doc_type\",\"chunk_id\",\"reasoning\",\"ctx_preview\"]])\n",
        "\n",
        "    # Options radio\n",
        "    opts = []\n",
        "    for idx, row in dfk.iterrows():\n",
        "        tag = \"OK\" if row.get(\"ok\") else (\"WARN\" if row.get(\"sanity_ok\") else \"NOK\")\n",
        "        label = f\"[{tag}] rank={row.get('context_rank')} | {row.get('value')} {row.get('unit')} ({row.get('year')}) — {row.get('doc_type')}# {row.get('chunk_id')}\"\n",
        "        opts.append((label, idx))\n",
        "    radio_candidates.options = opts\n",
        "    if opts:\n",
        "        radio_candidates.value = opts[0][1]\n",
        "\n",
        "    # Feature mapping par défaut\n",
        "    default_feature = KPI_TO_FEATURE_COL.get(k) or guess_feature_col_from_kpi(k) or FEATURE_COLS_TARGET[0]\n",
        "    feature_dropdown.value = default_feature\n",
        "\n",
        "def on_use_custom_change(change):\n",
        "    enabled = change[\"new\"]\n",
        "    val_input.disabled  = unit_input.disabled = year_input.disabled = isp_input.disabled = reas_input.disabled = (not enabled)\n",
        "    missing_value.disabled = (not enabled)  # AJOUT\n",
        "    if enabled:\n",
        "        missing_value.value = False  # AJOUT (reset propre)\n",
        "use_custom.observe(on_use_custom_change, names=\"value\")\n",
        "\n",
        "\n",
        "def on_missing_change(change):\n",
        "    is_missing = change[\"new\"]\n",
        "    val_input.disabled = is_missing or (not use_custom.value)\n",
        "\n",
        "missing_value.observe(on_missing_change, names=\"value\")\n",
        "\n",
        "\n",
        "def on_save_clicked(_):\n",
        "    p,k = kpi_index_by_label[kpi_select.value]\n",
        "    dfk = results_df[(results_df[\"pillar\"]==p) & (results_df[\"kpi_key\"]==k)].copy()\n",
        "    if dfk.empty:\n",
        "        return\n",
        "    dfk = _rank_candidates(dfk)\n",
        "\n",
        "    if not use_custom.value:\n",
        "        sel_idx = radio_candidates.value\n",
        "        row = dfk.iloc[sel_idx]\n",
        "        record = dict(\n",
        "            value = None if pd.isna(row.get(\"value\")) else float(row.get(\"value\")),\n",
        "            unit  = row.get(\"unit\"),\n",
        "            year  = None if pd.isna(row.get(\"year\")) else int(row.get(\"year\")),\n",
        "            is_present = bool(row.get(\"is_present\")),\n",
        "            reasoning  = row.get(\"reasoning\"),\n",
        "            feature_col = feature_dropdown.value,\n",
        "            source = {\n",
        "                \"context_rank\": int(row.get(\"context_rank\")) if not pd.isna(row.get(\"context_rank\")) else None,\n",
        "                \"doc_type\": row.get(\"doc_type\"),\n",
        "                \"chunk_id\": int(row.get(\"chunk_id\")) if not pd.isna(row.get(\"chunk_id\")) else None,\n",
        "                \"ok\": bool(row.get(\"ok\")),\n",
        "                \"sanity_ok\": bool(row.get(\"sanity_ok\")),\n",
        "                \"sanity_why\": row.get(\"sanity_why\"),\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        # Saisie manuelle\n",
        "        if missing_value.value:\n",
        "            val = None  # se transformera en NaN dans pandas pour une colonne float\n",
        "        else:\n",
        "            v = val_input.value\n",
        "            val = None if (v is None) else float(v)\n",
        "\n",
        "        record = dict(\n",
        "            value = None if (val_input.value is None) else float(val_input.value),\n",
        "            unit  = (unit_input.value or None),\n",
        "            year  = None if (year_input.value is None or year_input.value==0) else int(year_input.value),\n",
        "            is_present = bool(isp_input.value),\n",
        "            reasoning  = (reas_input.value or \"manual input\"),\n",
        "            feature_col = feature_dropdown.value,\n",
        "            source = {\"context_rank\": None, \"doc_type\": \"manual\", \"chunk_id\": None, \"ok\": True, \"sanity_ok\": True, \"sanity_why\": \"\"}\n",
        "        )\n",
        "\n",
        "    selected_map[(p,k)] = record\n",
        "\n",
        "    # Feedback\n",
        "    with status_out:\n",
        "        clear_output()\n",
        "        display(HTML(f\"<div class='hitl-card'><span class='ok-badge'>ENREGISTRÉ</span> {p} • <b>{k}</b> → \"\n",
        "                     f\"<b>{record['value']}</b> {record['unit'] or ''} ({record['year'] or '—'}) \"\n",
        "                     f\"→ feature <b>{record['feature_col']}</b></div>\"))\n",
        "    refresh_summary()\n",
        "\n",
        "def refresh_summary():\n",
        "    summary_out.clear_output()\n",
        "    if not selected_map:\n",
        "        return\n",
        "    rows = []\n",
        "    for (p,k), r in selected_map.items():\n",
        "        rows.append({\n",
        "            \"pillar\": p, \"kpi\": k, \"value\": r[\"value\"], \"unit\": r[\"unit\"], \"year\": r[\"year\"],\n",
        "            \"is_present\": r[\"is_present\"], \"feature_col\": r[\"feature_col\"], \"reasoning\": r[\"reasoning\"],\n",
        "            \"source_doc\": r[\"source\"].get(\"doc_type\"), \"ctx_rank\": r[\"source\"].get(\"context_rank\")\n",
        "        })\n",
        "    df_sel = pd.DataFrame(rows).sort_values([\"pillar\",\"kpi\"])\n",
        "    with summary_out:\n",
        "        display(HTML(\"<div class='hitl-title'>Sélections en cours</div>\"))\n",
        "        display(df_sel)\n",
        "\n",
        "def on_export_clicked(_):\n",
        "    audit_out.clear_output()\n",
        "    # Contrôles de base\n",
        "    if not sector_input.value.strip():\n",
        "        with audit_out:\n",
        "            display(HTML(\"<div class='hitl-card'><span class='err-badge'>ERREUR</span> Le champ <b>IVA_INDUSTRY</b> est obligatoire.</div>\"))\n",
        "        return\n",
        "\n",
        "    # Construire df_kpi_selected (audit) et df_features_ready (features modèle)\n",
        "    audit_rows = []\n",
        "    feat = {c: np.nan for c in FEATURE_COLS_TARGET}\n",
        "\n",
        "    # Métadonnées obligatoires & utiles\n",
        "    feat[\"ISSUER_CNTRY_DOMICILE\"] = (country_input.value or \"\").strip() or np.nan\n",
        "    feat[\"IVA_INDUSTRY\"] = sector_input.value.strip()\n",
        "\n",
        "    for (p,k), r in selected_map.items():\n",
        "        audit_rows.append({\n",
        "            \"pillar\": p, \"kpi\": k, \"value\": r[\"value\"], \"unit\": r[\"unit\"], \"year\": r[\"year\"],\n",
        "            \"is_present\": r[\"is_present\"], \"feature_col\": r[\"feature_col\"],\n",
        "            \"reasoning\": r[\"reasoning\"], \"source\": json.dumps(r[\"source\"], ensure_ascii=False)\n",
        "        })\n",
        "        # Injection dans la colonne feature (si présente)\n",
        "        col = r[\"feature_col\"]\n",
        "        if col in feat and r[\"value\"] is not None:\n",
        "            try:\n",
        "                feat[col] = float(r[\"value\"])\n",
        "            except:\n",
        "                feat[col] = r[\"value\"]\n",
        "\n",
        "    df_kpi_selected = pd.DataFrame(audit_rows).sort_values([\"pillar\",\"kpi\"]).reset_index(drop=True)\n",
        "    df_features_ready = pd.DataFrame([feat], columns=FEATURE_COLS_TARGET)\n",
        "\n",
        "    # Sauvegarde fichiers\n",
        "    RES_DIR = os.path.join(eng.cache_dir, \"human_in_the_loop\")\n",
        "    os.makedirs(RES_DIR, exist_ok=True)\n",
        "    rid = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    p_audit = os.path.join(RES_DIR, f\"selected_kpis_{cache_prefix}_{rid}.csv\")\n",
        "    p_feat  = os.path.join(RES_DIR, f\"features_{cache_prefix}_{rid}.csv\")\n",
        "    df_kpi_selected.to_csv(p_audit, index=False)\n",
        "    df_features_ready.to_csv(p_feat, index=False)\n",
        "\n",
        "    # Exposer dans le namespace global pour la cellule 3\n",
        "    globals()[\"df_kpi_selected\"] = df_kpi_selected\n",
        "    globals()[\"df_features_ready\"] = df_features_ready\n",
        "\n",
        "    with audit_out:\n",
        "        display(HTML(\"<div class='hitl-title'>Export terminé</div>\"))\n",
        "        display(HTML(f\"<div class='hitl-card'><span class='ok-badge'>OK</span> Audit → {p_audit}</div>\"))\n",
        "        display(HTML(f\"<div class='hitl-card'><span class='ok-badge'>OK</span> Features → {p_feat}</div>\"))\n",
        "        display(HTML(\"<div class='hitl-title'>Aperçu df_features_ready</div>\"))\n",
        "        display(df_features_ready)\n",
        "\n",
        "# --------- Liaisons ---------\n",
        "kpi_select.observe(refresh_candidates, names=\"value\")\n",
        "save_btn.on_click(on_save_clicked)\n",
        "export_btn.on_click(on_export_clicked)\n",
        "\n",
        "# --------- Mise en page ---------\n",
        "left_col  = w.VBox([\n",
        "    w.HTML(\"<h3>🧭 Revue par KPI</h3>\"),\n",
        "    kpi_select,\n",
        "    table_out,\n",
        "    w.HTML(\"<hr>\"),\n",
        "    w.HTML(\"<b>Choix du candidat</b>\"),\n",
        "    radio_candidates,\n",
        "    use_custom,\n",
        "    w.VBox([\n",
        "        w.HBox([val_input, unit_input, year_input]),\n",
        "        missing_value\n",
        "    ]),\n",
        "    isp_input,\n",
        "    reas_input,\n",
        "    w.HTML(\"<hr>\"),\n",
        "    feature_dropdown,\n",
        "    save_btn,\n",
        "    status_out\n",
        "], layout=w.Layout(width=\"65%\"))\n",
        "\n",
        "right_col = w.VBox([\n",
        "    w.HTML(\"<h3>🏷️ Métadonnées</h3>\"),\n",
        "    header_box,\n",
        "    w.HTML(\"<hr>\"),\n",
        "    w.HTML(\"<h3>✅ Sélections</h3>\"),\n",
        "    summary_out,\n",
        "    w.HTML(\"<hr>\"),\n",
        "    export_btn,\n",
        "    audit_out\n",
        "], layout=w.Layout(width=\"35%\"))\n",
        "\n",
        "display(w.HBox([left_col, right_col]))\n",
        "\n",
        "# Initialiser la vue\n",
        "refresh_candidates()\n",
        "refresh_summary()\n"
      ],
      "metadata": {
        "id": "-n8ZKHrySQ5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rating"
      ],
      "metadata": {
        "id": "z1OAZ6zPbgKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  [3/3] === Inférence XGBoost + correction secteur × bin(WA, pas=0.5) ===\n",
        "import json, os, numpy as np, pandas as pd, xgboost as xgb\n",
        "from packaging import version\n",
        "\n",
        "# 0) Préconditions\n",
        "assert \"df_features_ready\" in globals(), \"df_features_ready manquant. Utilisez la cellule [2/3] pour exporter les features.\"\n",
        "df_input = df_features_ready.copy()\n",
        "df_input = df_input.replace(-1, np.nan)\n",
        "# 1) Charger artefacts (depuis Google Drive)\n",
        "OUT_DIR = \"/content/drive/MyDrive/esg_rating_project/rating_module\"\n",
        "\n",
        "mdl = xgb.Booster()\n",
        "mdl.load_model(f\"{OUT_DIR}/xgb_model.json\")\n",
        "\n",
        "feat_meta = json.load(open(f\"{OUT_DIR}/feature_columns.json\", \"r\", encoding=\"utf-8\"))\n",
        "feature_cols_inf = feat_meta[\"feature_cols\"]\n",
        "cat_cols_inf     = set(feat_meta.get(\"cat_cols\", []))\n",
        "\n",
        "# 1bis) Tête secteur × bin(WA) — nouveau format (colonnes: sector, wa_bin, bias[, n_sb])\n",
        "path_s = f\"{OUT_DIR}/sector_bias.csv\"\n",
        "assert os.path.exists(path_s), \"sector_bias.csv introuvable. Exécutez la création de la tête binned d'abord.\"\n",
        "_bias_df = pd.read_csv(path_s)\n",
        "\n",
        "# Normaliser le type du bin (pas=0.5 → une décimale)\n",
        "if \"wa_bin\" not in _bias_df.columns or \"bias\" not in _bias_df.columns or \"sector\" not in _bias_df.columns:\n",
        "    raise ValueError(\"sector_bias.csv doit contenir les colonnes: 'sector', 'wa_bin', 'bias'.\")\n",
        "\n",
        "_bias_df[\"wa_bin\"] = pd.to_numeric(_bias_df[\"wa_bin\"], errors=\"coerce\")\n",
        "_bias_df[\"bias\"]   = pd.to_numeric(_bias_df[\"bias\"], errors=\"coerce\")\n",
        "\n",
        "# Tables de lookup\n",
        "_df_exact = _bias_df[_bias_df[\"wa_bin\"] >= 0][[\"sector\",\"wa_bin\",\"bias\"]].copy()\n",
        "_df_fb_s  = _bias_df[_bias_df[\"wa_bin\"] == -1].copy()\n",
        "\n",
        "_global_row = _df_fb_s[_df_fb_s[\"sector\"] == \"__GLOBAL__\"]\n",
        "global_bias = float(_global_row[\"bias\"].iloc[0]) if len(_global_row) else 0.0\n",
        "_df_fb_s = _df_fb_s[_df_fb_s[\"sector\"] != \"__GLOBAL__\"][[\"sector\",\"bias\"]].rename(columns={\"bias\":\"bias_sector\"})\n",
        "\n",
        "# Préparer structures pour nearest-bin (dans le même secteur)\n",
        "_dict_exact = {(r[\"sector\"], float(r[\"wa_bin\"])): float(r[\"bias\"]) for _, r in _df_exact.iterrows()}\n",
        "_bins_by_sector = {\n",
        "    s: np.sort(_df_exact.loc[_df_exact[\"sector\"]==s, \"wa_bin\"].dropna().astype(float).unique())\n",
        "    for s in _df_exact[\"sector\"].dropna().astype(str).unique()\n",
        "}\n",
        "\n",
        "# 2) Harmoniser colonnes d'inférence\n",
        "for c in feature_cols_inf:\n",
        "    if c not in df_input.columns:\n",
        "        df_input[c] = np.nan\n",
        "\n",
        "# Colonnes catégorielles\n",
        "use_native_cat = version.parse(xgb.__version__) >= version.parse(\"1.7.0\")\n",
        "for c in cat_cols_inf:\n",
        "    if c in df_input.columns:\n",
        "        df_input[c] = df_input[c].astype(\"category\")\n",
        "\n",
        "X_new = df_input[feature_cols_inf].copy()\n",
        "dnew = xgb.DMatrix(X_new, enable_categorical=use_native_cat)\n",
        "\n",
        "# 3) Prédiction brute (WA prédite)\n",
        "pred = mdl.predict(dnew)  # WA_pred\n",
        "\n",
        "# 4) Correction additive SECTEUR × BIN(WA, pas=0.5), avec bin tiré de ESG_SCORE_PRED si dispo\n",
        "sec_col = \"IVA_INDUSTRY\"\n",
        "sector_new = (\n",
        "    df_input[sec_col].astype(str).str.strip().replace({\"\": \"__MISSING__\"}).fillna(\"__MISSING__\")\n",
        "    if sec_col in df_input.columns else pd.Series([\"__MISSING__\"] * len(df_input), index=df_input.index)\n",
        ")\n",
        "\n",
        "# Source du bin : ESG_SCORE_PRED si déjà présent, sinon pred courant\n",
        "if \"ESG_SCORE_PRED\" in df_input.columns:\n",
        "    wa_for_binning = pd.to_numeric(df_input[\"ESG_SCORE_PRED\"], errors=\"coerce\").fillna(pred).values\n",
        "else:\n",
        "    wa_for_binning = pred\n",
        "\n",
        "# Bin pas=0.5 → {0.0, 0.5, 1.0, ..., 9.5}\n",
        "WA_clip = np.clip(wa_for_binning, 0.0, 9.999)\n",
        "wa_bin  = np.floor(WA_clip * 2) / 2.0\n",
        "wa_bin  = np.round(wa_bin, 1)\n",
        "\n",
        "lk = pd.DataFrame({\"sector\": sector_new.values, \"wa_bin\": wa_bin}, index=df_input.index)\n",
        "\n",
        "# 4.1) Jointure exacte (sector, wa_bin)\n",
        "lk = lk.merge(_df_exact, on=[\"sector\",\"wa_bin\"], how=\"left\")  # ajoute 'bias' (exact)\n",
        "\n",
        "# 4.2) Fallback nearest-bin (dans le même secteur)\n",
        "def _nearest_bias(row):\n",
        "    if not pd.isna(row.get(\"bias\")):\n",
        "        return row[\"bias\"], \"sector+bin\"\n",
        "    s = str(row[\"sector\"])\n",
        "    b = float(row[\"wa_bin\"])\n",
        "    bins = _bins_by_sector.get(s)\n",
        "    if bins is not None and len(bins) > 0:\n",
        "        nb = float(bins[np.argmin(np.abs(bins - b))])\n",
        "        val = _dict_exact.get((s, nb))\n",
        "        if val is not None:\n",
        "            return val, \"nearest-bin\"\n",
        "    return np.nan, None\n",
        "\n",
        "tmp = lk.apply(_nearest_bias, axis=1, result_type=\"expand\")\n",
        "lk[\"bias_nearest\"]     = pd.to_numeric(tmp[0], errors=\"coerce\")\n",
        "lk[\"bias_nearest_src\"] = tmp[1]\n",
        "\n",
        "# 4.3) Fallback sector-only (-1)\n",
        "lk = lk.merge(_df_fb_s, on=\"sector\", how=\"left\")  # ajoute 'bias_sector'\n",
        "\n",
        "# 4.4) Construire le vecteur final de biais (priorité: exact > nearest-bin > sector-only > global > 0)\n",
        "bias_vec = lk[\"bias\"].copy()\n",
        "bias_vec = bias_vec.fillna(lk[\"bias_nearest\"])\n",
        "bias_vec = bias_vec.fillna(lk[\"bias_sector\"])\n",
        "bias_vec = bias_vec.fillna(global_bias)\n",
        "bias_vec = bias_vec.fillna(0.0).astype(float).values\n",
        "\n",
        "# 4.5) Tracer la source utilisée\n",
        "bias_source = np.where(~pd.isna(lk[\"bias\"]), \"sector+bin\",\n",
        "                np.where(~pd.isna(lk[\"bias_nearest\"]), \"nearest-bin\",\n",
        "                np.where(~pd.isna(lk[\"bias_sector\"]), \"sector-only\",\n",
        "                \"__GLOBAL__\" if (global_bias != 0.0) else \"zero\")))\n",
        "\n",
        "# 5) Résultat\n",
        "pred_corrected = pred + bias_vec\n",
        "\n",
        "df_scored = df_input.copy()\n",
        "df_scored[\"SECTOR_NORM\"]          = sector_new.values\n",
        "df_scored[\"WA_BIN\"]               = wa_bin\n",
        "df_scored[\"BIAS_USED\"]            = bias_vec\n",
        "df_scored[\"BIAS_SOURCE\"]          = bias_source\n",
        "df_scored[\"ESG_SCORE_PRED\"]       = pred                # WA_pred\n",
        "df_scored[\"ESG_SCORE_PRED_FINAL\"] = pred_corrected      # IA_hat\n",
        "\n",
        "print(\"[OK] Scoring terminé. Aperçu :\")\n",
        "display(df_scored[[\"SECTOR_NORM\",\"WA_BIN\",\"BIAS_USED\",\"BIAS_SOURCE\",\"ESG_SCORE_PRED\",\"ESG_SCORE_PRED_FINAL\"]].head(3))\n"
      ],
      "metadata": {
        "id": "jnjQc_QUtN4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA FLUSH\n"
      ],
      "metadata": {
        "id": "jXwO4HN1uRAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% === PATCH & FLUSH CUDA GPU CACHE (à exécuter avant (re)load des modèles) ===\n",
        "import os, gc, time\n",
        "try:\n",
        "    import torch\n",
        "    has_cuda = torch.cuda.is_available()\n",
        "except Exception:\n",
        "    has_cuda = False\n",
        "\n",
        "# 👉 Patch allocator PyTorch (limite la fragmentation) — effectif pour les prochains allocs\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,garbage_collection_threshold:0.6,max_split_size_mb:128\"\n",
        "\n",
        "def gpu_mem_report(tag=\"\"):\n",
        "    if not has_cuda:\n",
        "        print(f\"[{tag}] CUDA indisponible.\"); return\n",
        "    free, total = torch.cuda.mem_get_info()\n",
        "    print(f\"[{tag}] GPU: free={free/1e9:.2f}GB / total={total/1e9:.2f}GB | \"\n",
        "          f\"reserved={torch.cuda.memory_reserved()/1e9:.2f}GB | \"\n",
        "          f\"allocated={torch.cuda.memory_allocated()/1e9:.2f}GB | \"\n",
        "          f\"max_alloc={torch.cuda.max_memory_allocated()/1e9:.2f}GB\")\n",
        "\n",
        "gpu_mem_report(\"AVANT\")\n",
        "\n",
        "# 👉 Optionnel: dé-référencer quelques objets connus si présents en global (modifie selon ton notebook)\n",
        "for name in (\"eng\",\"model\",\"embedding_model\",\"donut_model\",\"reranker\",\"tokenizer\"):\n",
        "    if name in globals():\n",
        "        try:\n",
        "            del globals()[name]\n",
        "            print(f\"del {name}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# 👉 GC Python + flush CUDA\n",
        "gc.collect()\n",
        "time.sleep(0.1)\n",
        "if has_cuda:\n",
        "    try:\n",
        "        torch.cuda.empty_cache()        # libère le cache du caching allocator\n",
        "        torch.cuda.ipc_collect()        # collecte les segments partagés\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        # (facultatif) relance TF32 pour NVIDIA modernes\n",
        "        try:\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "        except Exception:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        print(\"CUDA flush warning:\", e)\n",
        "\n",
        "time.sleep(0.1)\n",
        "gpu_mem_report(\"APRÈS\")\n",
        "\n",
        "print(\"\\n✅ Patch OK. Relance maintenant le chargement de tes modèles (HF/LLM/Donut).\")\n"
      ],
      "metadata": {
        "id": "qg8raXJGpWSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}